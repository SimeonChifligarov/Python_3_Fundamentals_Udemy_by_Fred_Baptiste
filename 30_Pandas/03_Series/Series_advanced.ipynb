{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Series — Advanced Practice (with Solutions)\n",
    "\n",
    "This notebook contains **advanced (but not too advanced)** practice problems on **`pandas.Series`**.\n",
    "\n",
    "**Best practices used here:**\n",
    "- Use **`loc` / `iloc`** explicitly to avoid ambiguous indexing.\n",
    "- Prefer **vectorized** operations over Python loops.\n",
    "- Make results **deterministic** (fixed seed where randomness is used).\n",
    "- Include **sanity checks** with `assert`.\n",
    "\n",
    "> Tip: Run each problem cell first, then compare with the solution cell right below it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 — Index alignment vs positional math\n",
    "\n",
    "You are given two Series with the **same values** but **different index orders**.\n",
    "\n",
    "1) Compute `a + b` (default behavior) and explain the result.\n",
    "2) Compute a **position-wise** sum (ignoring labels).\n",
    "3) Produce a final Series that keeps `a`'s index but sums values by position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([10, 20, 30], index=['x', 'y', 'z'])\n",
    "b = pd.Series([1,  2,  3],  index=['z', 'x', 'y'])\n",
    "\n",
    "# YOUR WORK:\n",
    "# 1) aligned_sum = ...\n",
    "# 2) positional_sum = ...\n",
    "# 3) final = ...\n",
    "# aligned_sum, positional_sum, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(x    12\n",
       " y    23\n",
       " z    31\n",
       " dtype: int64,\n",
       " array([11, 22, 33]),\n",
       " x    11\n",
       " y    22\n",
       " z    33\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "aligned_sum = a + b\n",
    "# Pandas aligns by label: x gets b['x']=2, y gets b['y']=3, z gets b['z']=1\n",
    "\n",
    "positional_sum = a.to_numpy() + b.to_numpy()\n",
    "final = pd.Series(positional_sum, index=a.index)\n",
    "\n",
    "aligned_sum, positional_sum, final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 — Reindexing with fill strategy and sanity checks\n",
    "\n",
    "Given a Series of daily revenue (some days missing):\n",
    "\n",
    "1) Reindex to a full daily range.\n",
    "2) Fill missing days with **0**.\n",
    "3) Compute a 3-day **rolling mean** (including zeros).\n",
    "4) Confirm the reindexed length via an `assert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = pd.Series(\n",
    "    [100, 180, 120],\n",
    "    index=pd.to_datetime(['2025-01-01', '2025-01-03', '2025-01-06'])\n",
    ")\n",
    "\n",
    "# YOUR WORK:\n",
    "# full_idx = ...\n",
    "# rev_full = ...\n",
    "# roll3 = ...\n",
    "# assert ...\n",
    "# rev_full, roll3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2025-01-01    100\n",
       " 2025-01-02      0\n",
       " 2025-01-03    180\n",
       " 2025-01-04      0\n",
       " 2025-01-05      0\n",
       " 2025-01-06    120\n",
       " Freq: D, dtype: int64,\n",
       " 2025-01-01          NaN\n",
       " 2025-01-02          NaN\n",
       " 2025-01-03    93.333333\n",
       " 2025-01-04    60.000000\n",
       " 2025-01-05    60.000000\n",
       " 2025-01-06    40.000000\n",
       " Freq: D, dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "full_idx = pd.date_range(rev.index.min(), rev.index.max(), freq='D')\n",
    "rev_full = rev.reindex(full_idx, fill_value=0)\n",
    "roll3 = rev_full.rolling(3).mean()\n",
    "\n",
    "assert len(rev_full) == len(full_idx)\n",
    "rev_full, roll3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 — `loc` vs `iloc` with integer labels (avoid the trap)\n",
    "\n",
    "You are given a Series with **integer labels** that are not positional indices.\n",
    "\n",
    "1) Select the value whose **label** is `20`.\n",
    "2) Select the value at **position** 1.\n",
    "3) Slice labels from 10 to 30 (inclusive).\n",
    "4) Slice positions 0 to 2 (exclusive of 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([7, 8, 9], index=[10, 20, 30])\n",
    "\n",
    "# YOUR WORK:\n",
    "# label_20 = ...\n",
    "# pos_1 = ...\n",
    "# label_slice = ...\n",
    "# pos_slice = ...\n",
    "# label_20, pos_1, label_slice, pos_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(8),\n",
       " np.int64(8),\n",
       " 10    7\n",
       " 20    8\n",
       " 30    9\n",
       " dtype: int64,\n",
       " 10    7\n",
       " 20    8\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "label_20 = s.loc[20]\n",
    "pos_1 = s.iloc[1]\n",
    "label_slice = s.loc[10:30]     # inclusive\n",
    "pos_slice = s.iloc[0:2]       # exclusive end\n",
    "\n",
    "label_20, pos_1, label_slice, pos_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 — Duplicate index: targeted update without overwriting all matches\n",
    "\n",
    "You have a Series with **duplicate labels**.\n",
    "\n",
    "Task:\n",
    "- Change **only the second** occurrence of label `'city'` to `'London'`.\n",
    "- Do **not** change other `'city'` rows.\n",
    "\n",
    "Hint: Use boolean logic plus `cumcount()` (via `groupby(level=0)`) or operate by positional index once you identify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = pd.Series(\n",
    "    ['USA', 'Topeka', 'France', 'Lyon', 'UK', 'Glasgow'],\n",
    "    index=['country', 'city', 'country', 'city', 'country', 'city'],\n",
    "    name='Areas'\n",
    ")\n",
    "\n",
    "# YOUR WORK:\n",
    "# updated = ...\n",
    "# updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country        USA\n",
       "city        Topeka\n",
       "country     France\n",
       "city        London\n",
       "country         UK\n",
       "city       Glasgow\n",
       "Name: Areas, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "updated = areas.copy()\n",
    "\n",
    "# Identify the second occurrence of each label by order within the label group\n",
    "occ = updated.groupby(level=0).cumcount()  # 0,1,2... within each label\n",
    "mask = (updated.index == 'city') & (occ == 1)  # second 'city'\n",
    "\n",
    "updated.loc[mask] = 'London'\n",
    "updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 — Combining two Series with different coverage (`combine_first`)\n",
    "\n",
    "You have two data sources for the same metric. `primary` is preferred, but it has missing values.\n",
    "\n",
    "1) Create a final Series that uses `primary` where available, otherwise falls back to `backup`.\n",
    "2) Show how many values came from the fallback.\n",
    "3) Verify that the final has no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary = pd.Series([1.1, np.nan, 3.3, np.nan], index=list('abcd'))\n",
    "backup  = pd.Series([1.0, 2.2, np.nan, 4.4], index=list('abcd'))\n",
    "\n",
    "# YOUR WORK:\n",
    "# final = ...\n",
    "# fallback_count = ...\n",
    "# assert ...\n",
    "# final, fallback_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(a    1.1\n",
       " b    2.2\n",
       " c    3.3\n",
       " d    4.4\n",
       " dtype: float64,\n",
       " 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "final = primary.combine_first(backup)\n",
    "fallback_count = primary.isna().sum()  # positions where fallback could be used\n",
    "\n",
    "assert final.notna().all()\n",
    "final, int(fallback_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6 — Fast wins: replace a slow loop with vectorization\n",
    "\n",
    "You have a Series of prices and want to compute a **tiered fee**:\n",
    "- fee is 2% if price < 100\n",
    "- fee is 1% otherwise\n",
    "\n",
    "1) Compute fees **without** a Python loop.\n",
    "2) Return a Series of fees with the same index.\n",
    "3) Confirm the dtype is float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.Series([50, 120, 80, 200], index=['p1', 'p2', 'p3', 'p4'])\n",
    "\n",
    "# YOUR WORK:\n",
    "# fees = ...\n",
    "# assert ...\n",
    "# fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p1    1.0\n",
       "p2    1.2\n",
       "p3    1.6\n",
       "p4    2.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "rates = np.where(prices < 100, 0.02, 0.01)\n",
    "fees = prices * rates\n",
    "\n",
    "assert isinstance(fees, pd.Series)\n",
    "assert fees.dtype.kind == 'f'\n",
    "fees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7 — Normalize and report top categories (robust output)\n",
    "\n",
    "Given a Series of event types, compute:\n",
    "1) counts per category\n",
    "2) percentage share (sums to 1)\n",
    "3) a clean summary Series that contains only the **top 2** categories by count, labeled like `\"A (50.0%)\"`.\n",
    "\n",
    "Make sure your code works even if there are ties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.Series(['A', 'B', 'A', 'C', 'A', 'B', 'C', 'A', 'B', 'B'])\n",
    "\n",
    "# YOUR WORK:\n",
    "# counts = ...\n",
    "# share = ...\n",
    "# top2 = ...\n",
    "# counts, share, top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(A    4\n",
       " B    4\n",
       " C    2\n",
       " Name: count, dtype: int64,\n",
       " A    0.4\n",
       " B    0.4\n",
       " C    0.2\n",
       " Name: proportion, dtype: float64,\n",
       " A    A (40.0%)\n",
       " B    B (40.0%)\n",
       " Name: Top2, dtype: object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "counts = events.value_counts(dropna=False)\n",
    "share = events.value_counts(normalize=True, dropna=False)\n",
    "\n",
    "top2_idx = counts.nlargest(2).index\n",
    "top2 = pd.Series(\n",
    "    [f\"{k} ({share.loc[k]*100:.1f}%)\" for k in top2_idx],\n",
    "    index=top2_idx,\n",
    "    name='Top2'\n",
    ")\n",
    "\n",
    "assert abs(share.sum() - 1.0) < 1e-12\n",
    "counts, share, top2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8 — Map vs replace: standardize messy labels safely\n",
    "\n",
    "You have inconsistent country labels.\n",
    "\n",
    "Requirements:\n",
    "- Standardize using a mapping.\n",
    "- Unknown values should remain unchanged.\n",
    "- Produce a final Series and also a boolean Series indicating which entries were changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.Series(['UK', 'U.K.', 'United Kingdom', 'USA', 'U.S.A.', 'Canada'])\n",
    "mapping = {\n",
    "    'UK': 'United Kingdom',\n",
    "    'U.K.': 'United Kingdom',\n",
    "    'USA': 'United States',\n",
    "    'U.S.A.': 'United States'\n",
    "}\n",
    "\n",
    "# YOUR WORK:\n",
    "# standardized = ...\n",
    "# changed = ...\n",
    "# standardized, changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    United Kingdom\n",
       " 1    United Kingdom\n",
       " 2    United Kingdom\n",
       " 3     United States\n",
       " 4     United States\n",
       " 5            Canada\n",
       " dtype: object,\n",
       " 0     True\n",
       " 1     True\n",
       " 2    False\n",
       " 3     True\n",
       " 4     True\n",
       " 5    False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# map() turns non-mapped values into NaN, so we use fillna(original) to keep unknowns\n",
    "mapped = countries.map(mapping)\n",
    "standardized = mapped.fillna(countries)\n",
    "changed = standardized.ne(countries)\n",
    "\n",
    "standardized, changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9 — MultiIndex Series: slice and aggregate by one level\n",
    "\n",
    "You have a Series indexed by `(store, day)`.\n",
    "\n",
    "Tasks:\n",
    "1) Get all data for store `'S2'`.\n",
    "2) Compute total per store.\n",
    "3) Compute the best (max) day per store and return just the **day label** for each store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.MultiIndex.from_product(\n",
    "    [['S1', 'S2'], pd.to_datetime(['2025-02-01', '2025-02-02', '2025-02-03'])],\n",
    "    names=['store', 'day']\n",
    ")\n",
    "sales = pd.Series([10, 12, 11,  7, 15,  9], index=idx, name='sales')\n",
    "\n",
    "# YOUR WORK:\n",
    "# s2 = ...\n",
    "# totals = ...\n",
    "# best_day = ...\n",
    "# s2, totals, best_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(day\n",
       " 2025-02-01     7\n",
       " 2025-02-02    15\n",
       " 2025-02-03     9\n",
       " Name: sales, dtype: int64,\n",
       " store\n",
       " S1    33\n",
       " S2    31\n",
       " Name: sales, dtype: int64,\n",
       " store\n",
       " S1   2025-02-02\n",
       " S2   2025-02-02\n",
       " Name: best_day, dtype: datetime64[ns])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "s2 = sales.loc['S2']\n",
    "totals = sales.groupby(level='store').sum()\n",
    "\n",
    "# idxmax gives the full MultiIndex key; we then extract the 'day' level\n",
    "best_key = sales.groupby(level='store').idxmax()\n",
    "best_day = best_key.map(lambda t: t[1])\n",
    "best_day.name = 'best_day'\n",
    "\n",
    "s2, totals, best_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10 — Safe deletion: drop by position (without guessing labels)\n",
    "\n",
    "Given a Series with a non-trivial index, drop rows by **position**.\n",
    "\n",
    "Tasks:\n",
    "1) Drop the first and last elements by position.\n",
    "2) Return a new Series (do not mutate the original).\n",
    "3) Confirm original Series is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([100, 200, 300, 400], index=['alpha', 'beta', 'gamma', 'delta'], name='vals')\n",
    "\n",
    "# YOUR WORK:\n",
    "# dropped = ...\n",
    "# assert ...\n",
    "# s, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(alpha    100\n",
       " beta     200\n",
       " gamma    300\n",
       " delta    400\n",
       " Name: vals, dtype: int64,\n",
       " beta     200\n",
       " gamma    300\n",
       " Name: vals, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "to_drop_labels = s.index[[0, -1]]\n",
    "dropped = s.drop(to_drop_labels)\n",
    "\n",
    "assert s.index.tolist() == ['alpha', 'beta', 'gamma', 'delta']  # unchanged\n",
    "s, dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
