{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b8f9e9",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-invalid",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-vocabulary",
   "metadata": {},
   "source": [
    "Alongside this notebook is a data file named `daily_quotes.csv` which contains EOD OHLC/Volume data for a small number of equities over a 6 month period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-orlando",
   "metadata": {},
   "source": [
    "The first step is to load up this data into a dataframe, ensuring that all data types are correct (datetime objects for dates, floats for OHLC data, and integers for Volume)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-collection",
   "metadata": {},
   "source": [
    "Write a function that receives the file name as an argument and returns a dataframe that:\n",
    "- has the correct data type for each column (`str`, `float`, `int`)\n",
    "- has a row index based on the `symbol` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-daily",
   "metadata": {},
   "source": [
    "In addition, we would like our dataframe to contain columns named and ordered in a specific way:\n",
    "- symbol (`str`)\n",
    "- date (`datetime`)\n",
    "- open (`float`)\n",
    "- high (`float`)\n",
    "- low (`float`)\n",
    "- close (`float`)\n",
    "- volume (`int`)\n",
    "\n",
    "(with `symbol` being used as the row index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-correspondence",
   "metadata": {},
   "source": [
    "Hint: \n",
    "\n",
    "You will want to read up the Pandas docs for `read_csv` to see how you can handle datetime data directly while loading the data (in particular you should look at the `parse_dates` option):\n",
    "\n",
    "[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    ")\n",
    "\n",
    "Alternatively, you could convert these objects into proper datetime types after loading by using the Pandas function `to_datetime`, documented here:\n",
    "\n",
    "[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    ")\n",
    "\n",
    "and then use concatenation to build up a dataframe that replaces the \"old\" `date` column with the \"new\" (properly typed) column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "q1-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_daily_quotes(csv_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    csv_path = Path(csv_path)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "\n",
    "    # Load without parse_dates first\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Normalize column names (VERY important)\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "    )\n",
    "\n",
    "    required_cols = [\"symbol\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required column(s): {missing}\")\n",
    "\n",
    "    # Type conversions\n",
    "    df[\"symbol\"] = df[\"symbol\"].astype(\"string\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"raise\")\n",
    "\n",
    "    for col in [\"open\", \"high\", \"low\", \"close\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"raise\").astype(\"float64\")\n",
    "\n",
    "    vol = pd.to_numeric(df[\"volume\"], errors=\"raise\")\n",
    "    df[\"volume\"] = vol.astype(\"Int64\") if vol.isna().any() else vol.astype(\"int64\")\n",
    "\n",
    "    # Enforce column order\n",
    "    df = df[required_cols]\n",
    "\n",
    "    # Set index but keep symbol column\n",
    "    df = df.set_index(\"symbol\", drop=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def load_daily_quotes(csv_path: Union[str, Path]) -> pd.DataFrame:\n",
    "    \"\"\"Load daily EOD quotes from a CSV into a well-typed DataFrame.\n",
    "\n",
    "    Requirements satisfied:\n",
    "    - date parsed as datetime\n",
    "    - OHLC as float\n",
    "    - volume as int\n",
    "    - symbol kept as a column but also used as the row index\n",
    "    - columns ordered exactly as: symbol, date, open, high, low, close, volume\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_path:\n",
    "        Path to the CSV file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame indexed by symbol.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "\n",
    "    required_cols = [\"symbol\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "    # Read with strong dtype hints. We parse date at read-time.\n",
    "    # Note: volume may contain missing values in some datasets; we guard below.\n",
    "    df = pd.read_csv(\n",
    "        csv_path,\n",
    "        parse_dates=[\"date\"],\n",
    "        dtype={\n",
    "            \"symbol\": \"string\",\n",
    "            \"open\": \"float64\",\n",
    "            \"high\": \"float64\",\n",
    "            \"low\": \"float64\",\n",
    "            \"close\": \"float64\",\n",
    "        },\n",
    "        keep_default_na=True,\n",
    "    )\n",
    "\n",
    "    missing = [c for c in required_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required column(s): {missing}\")\n",
    "\n",
    "    # Ensure volume is integer (nullable safe conversion).\n",
    "    # If volume has no missing values, we downcast to a regular int64.\n",
    "    vol = pd.to_numeric(df[\"volume\"], errors=\"raise\")\n",
    "    if vol.isna().any():\n",
    "        df[\"volume\"] = vol.astype(\"Int64\")\n",
    "    else:\n",
    "        df[\"volume\"] = vol.astype(\"int64\")\n",
    "\n",
    "    # Ensure date is datetime even if parse_dates didn't trigger due to upstream formatting.\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"raise\")\n",
    "\n",
    "    # Enforce column order.\n",
    "    df = df[required_cols]\n",
    "\n",
    "    # Set index to symbol but keep symbol column.\n",
    "    df = df.set_index(\"symbol\", drop=False)\n",
    "\n",
    "    # Defensive: consistent string dtype for symbol column.\n",
    "    df[\"symbol\"] = df[\"symbol\"].astype(\"string\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage (uncomment if you want to run it):\n",
    "# quotes = load_daily_quotes(\"daily_quotes.csv\")\n",
    "# quotes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-chaos",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-communication",
   "metadata": {},
   "source": [
    "Write a function that, given a dataframe sructured as the one we created in Question 1 and a symbol name as a string (e.g. `AAPL`, `MSFT`, etc), will:\n",
    "- return a similarly structured dataframe consisting of the row (or rows) containing the records with the highest volume for the given symbol\n",
    "- raises a `ValueError` if the symbol is not in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "q2-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def rows_with_max_volume(df: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"Return the row(s) with the highest volume for a given symbol.\n",
    "\n",
    "    The returned DataFrame keeps the same structure as the input.\n",
    "    Raises ValueError if the symbol does not exist.\n",
    "    \"\"\"\n",
    "    if \"symbol\" not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain a 'symbol' column.\")\n",
    "\n",
    "    symbol = str(symbol)\n",
    "    # Use the symbol column for filtering (robust even if index changes).\n",
    "    sub = df.loc[df[\"symbol\"] == symbol]\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"Symbol not found in dataframe: {symbol}\")\n",
    "\n",
    "    max_vol = sub[\"volume\"].max()\n",
    "    return sub.loc[sub[\"volume\"] == max_vol]\n",
    "\n",
    "\n",
    "# Example (uncomment):\n",
    "# rows_with_max_volume(quotes, \"AAPL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-facing",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-margin",
   "metadata": {},
   "source": [
    "Using the same dataframe as in the preceding questions, our goal now is to write a function that will return, for a specific symbol, the row that had the largest high-low spread."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-litigation",
   "metadata": {},
   "source": [
    "Write a function to do that - it should just return a dataframe with the row (or rows) with the largest high-low spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "q3-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def rows_with_max_spread_for_symbol(df: pd.DataFrame, symbol: str) -> pd.DataFrame:\n",
    "    \"\"\"Return the row(s) for `symbol` with the largest (high - low) spread.\n",
    "\n",
    "    Returns a DataFrame (possibly multiple rows if ties).\n",
    "    Raises ValueError if symbol not present.\n",
    "    \"\"\"\n",
    "    required = {\"symbol\", \"high\", \"low\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Input DataFrame missing required column(s): {sorted(missing)}\")\n",
    "\n",
    "    symbol = str(symbol)\n",
    "    sub = df.loc[df[\"symbol\"] == symbol]\n",
    "    if sub.empty:\n",
    "        raise ValueError(f\"Symbol not found in dataframe: {symbol}\")\n",
    "\n",
    "    spread = sub[\"high\"] - sub[\"low\"]\n",
    "    max_spread = spread.max()\n",
    "    return sub.loc[spread == max_spread]\n",
    "\n",
    "\n",
    "# Example (uncomment):\n",
    "# rows_with_max_spread_for_symbol(quotes, \"MSFT\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-magazine",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-coral",
   "metadata": {},
   "source": [
    "Using the same dataframe as the preceding questions, write a function that returns a single dataframe containing the record(s) with maximum high-low spread for each symbol in the dataframe. (Do not hardcode symbol names in this function - instead you should recover the possible symbol names from the data itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-oriental",
   "metadata": {},
   "source": [
    "The returned dataframe should have the same structure as the original dataframe, but just contain the rows of maximum high-low spread for each symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "q4-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def rows_with_max_spread_per_symbol(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame containing the row(s) of maximum (high - low) spread for each symbol.\n",
    "\n",
    "    - Does not hardcode symbol names.\n",
    "    - Preserves the input DataFrame structure and column set.\n",
    "    - If multiple rows tie for max spread within a symbol, all tied rows are included.\n",
    "    \"\"\"\n",
    "    required = {\"symbol\", \"high\", \"low\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Input DataFrame missing required column(s): {sorted(missing)}\")\n",
    "\n",
    "    # Compute spread once for grouping operations.\n",
    "    spread = df[\"high\"] - df[\"low\"]\n",
    "\n",
    "    # For each symbol, compute its maximum spread.\n",
    "    max_spread_by_symbol = spread.groupby(df[\"symbol\"]).transform(\"max\")\n",
    "\n",
    "    # Keep rows whose spread equals the per-symbol maximum.\n",
    "    out = df.loc[spread == max_spread_by_symbol].copy()\n",
    "\n",
    "    # Optional: stable ordering (by symbol then date if date exists).\n",
    "    sort_cols = [\"symbol\"] + ([\"date\"] if \"date\" in out.columns else [])\n",
    "    out = out.sort_values(sort_cols)\n",
    "\n",
    "    # Preserve the same kind of index semantics as Q1 if present:\n",
    "    # if the input is indexed by symbol and also has a symbol column, keep that convention.\n",
    "    if df.index.name == \"symbol\" and \"symbol\" in out.columns:\n",
    "        out = out.set_index(\"symbol\", drop=False)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Example end-to-end (uncomment):\n",
    "# quotes = load_daily_quotes(\"daily_quotes.csv\")\n",
    "# rows_with_max_spread_per_symbol(quotes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "explore-invocation-issues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exploration: function invocation issues ---\n",
      "\n",
      "[Q1] Checking CSV path and working directory\n",
      "Current working directory: D:\\_Udemy_course_PRACTICE\\Python_3_Fundamentals_Udemy_by_Fred_Baptiste\\30_Pandas\\11_Exercises\n",
      "Does daily_quotes.csv exist here? True\n",
      "✅ CSV file found\n",
      "\n",
      "[Q1] Inspecting dataframe structure\n",
      "❌ Error while loading dataframe:\n",
      "ValueError: Missing column provided to 'parse_dates': 'date'\n",
      "\n",
      "[Q2/Q3] Exploring symbol-related issues\n",
      "\n",
      "[Q2–Q4] Exploring missing-column problems\n",
      "\n",
      "[Index vs Column] Exploring index-related confusion\n",
      "\n",
      "[Q4] Inspecting per-symbol spread calculation\n",
      "\n",
      "--- End of invocation exploration ---\n"
     ]
    }
   ],
   "source": [
    "# Exploratory cell: common problems when invoking the solution functions\n",
    "# This cell is meant for *diagnostics*, not correctness tests.\n",
    "# Run sections one by one and read the printed output / raised errors.\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"--- Exploration: function invocation issues ---\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. File path and working-directory issues (Q1)\n",
    "# -------------------------------------------------\n",
    "print(\"\\n[Q1] Checking CSV path and working directory\")\n",
    "print(\"Current working directory:\", Path.cwd())\n",
    "\n",
    "csv_path = Path(\"daily_quotes.csv\")\n",
    "print(\"Does daily_quotes.csv exist here?\", csv_path.exists())\n",
    "\n",
    "if not csv_path.exists():\n",
    "    print(\n",
    "        \"❌ Problem: daily_quotes.csv not found.\\n\"\n",
    "        \"   - Ensure the file is in the same directory as this notebook, OR\\n\"\n",
    "        \"   - Pass an absolute / correct relative path to load_daily_quotes().\"\n",
    "    )\n",
    "else:\n",
    "    print(\"✅ CSV file found\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Inspecting the loaded dataframe (Q1)\n",
    "# -------------------------------------------------\n",
    "print(\"\\n[Q1] Inspecting dataframe structure\")\n",
    "\n",
    "try:\n",
    "    quotes = load_daily_quotes(csv_path)\n",
    "    print(\"DataFrame loaded successfully\")\n",
    "    print(\"Shape:\", quotes.shape)\n",
    "    print(\"Columns:\", list(quotes.columns))\n",
    "    print(\"Index name:\", quotes.index.name)\n",
    "    print(\"Dtypes:\\n\", quotes.dtypes)\n",
    "except Exception as e:\n",
    "    print(\"❌ Error while loading dataframe:\")\n",
    "    print(type(e).__name__ + \":\", e)\n",
    "    quotes = None\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Symbol handling pitfalls (Q2, Q3)\n",
    "# -------------------------------------------------\n",
    "print(\"\\n[Q2/Q3] Exploring symbol-related issues\")\n",
    "\n",
    "if quotes is not None:\n",
    "    unique_symbols = quotes[\"symbol\"].astype(str).unique().tolist()\n",
    "    print(\"Available symbols:\", unique_symbols)\n",
    "\n",
    "    # Common mistake: wrong casing or whitespace\n",
    "    test_symbol = unique_symbols[0]\n",
    "    print(\"Using test symbol:\", repr(test_symbol))\n",
    "\n",
    "    print(\"Trying correct symbol → should succeed\")\n",
    "    try:\n",
    "        rows_with_max_volume(quotes, test_symbol)\n",
    "        rows_with_max_spread_for_symbol(quotes, test_symbol)\n",
    "        print(\"✅ Correct symbol invocation works\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Unexpected error with valid symbol:\", e)\n",
    "\n",
    "    print(\"\\nTrying incorrect symbol → should fail\")\n",
    "    try:\n",
    "        rows_with_max_volume(quotes, \"not_a_real_symbol\")\n",
    "    except Exception as e:\n",
    "        print(\"Expected failure:\", type(e).__name__, e)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Column dependency issues (Q2–Q4)\n",
    "# -------------------------------------------------\n",
    "print(\"\\n[Q2–Q4] Exploring missing-column problems\")\n",
    "\n",
    "if quotes is not None:\n",
    "    # Simulate a user accidentally dropping a required column\n",
    "    broken_df = quotes.drop(columns=[\"low\"])\n",
    "    print(\"Dropped column 'low'. Columns now:\", list(broken_df.columns))\n",
    "\n",
    "    try:\n",
    "        rows_with_max_spread_for_symbol(broken_df, test_symbol)\n",
    "    except Exception as e:\n",
    "        print(\"Expected failure due to missing column:\", type(e).__name__, e)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Index vs column confusion\n",
    "# -------------------------------------------------\n",
    "print(\"\\n[Index vs Column] Exploring index-related confusion\")\n",
    "\n",
    "if quotes is not None:\n",
    "    print(\"Index name:\", quotes.index.name)\n",
    "    print(\"Is 'symbol' also a column?\", \"symbol\" in quotes.columns)\n",
    "\n",
    "    # Common pitfall: user assumes symbol is only in the index\n",
    "    df_no_symbol_col = quotes.drop(columns=[\"symbol\"])\n",
    "    print(\"Removed 'symbol' column, relying only on index\")\n",
    "\n",
    "    try:\n",
    "        rows_with_max_volume(df_no_symbol_col, test_symbol)\n",
    "    except Exception as e:\n",
    "        print(\"Expected failure when 'symbol' column is missing:\", type(e).__name__, e)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Sanity check for Q4 grouping logic\n",
    "# -------------------------------------------------\n",
    "print(\"\\n[Q4] Inspecting per-symbol spread calculation\")\n",
    "\n",
    "if quotes is not None:\n",
    "    try:\n",
    "        q4_out = rows_with_max_spread_per_symbol(quotes)\n",
    "        print(\"Q4 output shape:\", q4_out.shape)\n",
    "        print(\"Symbols in output:\", q4_out[\"symbol\"].unique().tolist())\n",
    "        print(\"Sample output rows:\\n\", q4_out.head())\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error invoking Q4:\", type(e).__name__, e)\n",
    "\n",
    "\n",
    "print(\"\\n--- End of invocation exploration ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c82f4e-274e-4e92-be36-2577ad63de90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
