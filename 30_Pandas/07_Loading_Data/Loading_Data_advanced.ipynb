{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Loading Data — Advanced Practice (with Solutions)\n",
    "\n",
    "This notebook contains several **advanced (but not too advanced)** problems about loading data with Pandas.\n",
    "\n",
    "**Best practices used here:**\n",
    "- No external files required (we use in-memory CSV/Excel).\n",
    "- Explicit dtypes, parsing dates, and handling missing values.\n",
    "- Validation checks (`assert`) to catch silent issues early.\n",
    "- Clear separation of problems and solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data (in-memory)\n",
    "\n",
    "We'll create a messy CSV and a multi-sheet Excel workbook in memory so you can run everything anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV and Excel data prepared in memory.\n"
     ]
    }
   ],
   "source": [
    "csv_text = \"\"\"Geographic Area,July 1, 2001 Estimate,July 1, 2000 Estimate,April 1, 2000 Population Estimates Base,notes\n",
    "North,  1200 , 1150 , 1148 , ok\n",
    "South,  980  ,  990 ,  988 , revised\n",
    "East,   N/A  , 1050 , 1049 , missing 2001\n",
    "West,   1500 ,  0   , 1490 , zero baseline\n",
    "Central, 1100, 1090 , 1088 , ok\n",
    "\"\"\"\n",
    "\n",
    "# Multi-sheet Excel (as bytes)\n",
    "excel_bytes = BytesIO()\n",
    "with pd.ExcelWriter(excel_bytes, engine=\"openpyxl\") as writer:\n",
    "    pd.DataFrame({\n",
    "        \"region\": [\"North\", \"South\", \"East\", \"West\", \"Central\"],\n",
    "        \"2001\": [1200, 980, np.nan, 1500, 1100],\n",
    "        \"2000\": [1150, 990, 1050, 0, 1090],\n",
    "        \"status\": [\"ok\", \"revised\", \"ok\", \"ok\", \"ok\"]\n",
    "    }).to_excel(writer, sheet_name=\"data\", index=False)\n",
    "\n",
    "    pd.DataFrame({\n",
    "        \"region\": [\"North\", \"South\", \"East\", \"West\", \"Central\"],\n",
    "        \"manager\": [\"Ava\", \"Noah\", \"Mia\", \"Liam\", \"Ema\"],\n",
    "        \"opened\": [\"2000-01-15\", \"1998-07-01\", \"2001-03-20\", \"1999-11-05\", \"2000-06-30\"],\n",
    "    }).to_excel(writer, sheet_name=\"metadata\", index=False)\n",
    "\n",
    "excel_bytes.seek(0)\n",
    "\n",
    "print(\"CSV and Excel data prepared in memory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 — Load, rename, select columns, set index (CSV)\n",
    "\n",
    "**Task**\n",
    "1. Load the CSV from `csv_text` into a DataFrame.\n",
    "2. Keep only the columns corresponding to region, 2001 estimate, 2000 estimate.\n",
    "3. Rename columns to: `region`, `2001`, `2000`.\n",
    "4. Set `region` as the index.\n",
    "5. Ensure `2001` and `2000` are numeric and missing values are properly set to `NaN`.\n",
    "\n",
    "**Expected outcome**\n",
    "- Index is `region`.\n",
    "- `2001` has a missing value for `East`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>980.0</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2001  2000\n",
       "region               \n",
       "North    1200.0  1150\n",
       "South     980.0   990\n",
       "East        NaN  1050\n",
       "West     1500.0     0\n",
       "Central  1100.0  1090"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 1\n",
    "df1 = pd.read_csv(\n",
    "    StringIO(csv_text),\n",
    "    header=0,\n",
    "    usecols=[0, 1, 2],\n",
    "    names=[\"region\", \"2001\", \"2000\"],\n",
    "    index_col=0,\n",
    "    skipinitialspace=True,\n",
    "    na_values=[\"N/A\", \"NA\", \"\"],\n",
    ")\n",
    "\n",
    "# Convert to numeric robustly (handles any stray whitespace/strings)\n",
    "df1[\"2001\"] = pd.to_numeric(df1[\"2001\"], errors=\"coerce\")\n",
    "df1[\"2000\"] = pd.to_numeric(df1[\"2000\"], errors=\"coerce\")\n",
    "\n",
    "display(df1)\n",
    "\n",
    "assert df1.index.name == \"region\"\n",
    "assert set(df1.columns) == {\"2001\", \"2000\"}\n",
    "assert np.isnan(df1.loc[\"East\", \"2001\"])\n",
    "assert df1[[\"2001\", \"2000\"]].dtypes.apply(lambda x: np.issubdtype(x, np.number)).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 — Compute growth % safely (division by zero)\n",
    "\n",
    "**Task**\n",
    "Using `df1`, compute the percent growth from 2000 to 2001:\n",
    "\n",
    "\\[ growth\\_pct = 100 * (2001 - 2000) / 2000 \\]\n",
    "\n",
    "But handle edge cases:\n",
    "- If `2000` is 0, return `NaN` (avoid infinite).\n",
    "- If `2001` is missing, return `NaN`.\n",
    "\n",
    "**Expected outcome**\n",
    "- `West` should be `NaN` because 2000 is 0.\n",
    "- `East` should be `NaN` because 2001 is missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "North      4.347826\n",
       "South     -1.010101\n",
       "East            NaN\n",
       "West            NaN\n",
       "Central    0.917431\n",
       "Name: growth_pct, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 2\n",
    "den = df1[\"2000\"].where(df1[\"2000\"] != 0)  # turn 0 into NaN\n",
    "growth_pct = 100 * (df1[\"2001\"] - df1[\"2000\"]) / den\n",
    "growth_pct = growth_pct.rename(\"growth_pct\")\n",
    "\n",
    "display(growth_pct)\n",
    "\n",
    "assert np.isnan(growth_pct.loc[\"West\"])  # division by zero avoided\n",
    "assert np.isnan(growth_pct.loc[\"East\"])  # missing 2001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 — Validate schema and values (defensive loading)\n",
    "\n",
    "**Task**\n",
    "Write a function `load_population_csv(text: str) -> pd.DataFrame` that:\n",
    "- Loads the CSV from a string.\n",
    "- Produces the same structure as `df1`.\n",
    "- Validates:\n",
    "  - Index has **no duplicates**.\n",
    "  - Columns are exactly `2001` and `2000`.\n",
    "  - Values are non-negative (ignore NaNs).\n",
    "\n",
    "**Return** the cleaned DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>980.0</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2001  2000\n",
       "region               \n",
       "North    1200.0  1150\n",
       "South     980.0   990\n",
       "East        NaN  1050\n",
       "West     1500.0     0\n",
       "Central  1100.0  1090"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 3\n",
    "def load_population_csv(text: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\n",
    "        StringIO(text),\n",
    "        header=0,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=[\"region\", \"2001\", \"2000\"],\n",
    "        index_col=0,\n",
    "        skipinitialspace=True,\n",
    "        na_values=[\"N/A\", \"NA\", \"\"],\n",
    "    )\n",
    "\n",
    "    for c in [\"2001\", \"2000\"]:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Validations\n",
    "    if df.index.has_duplicates:\n",
    "        dupes = df.index[df.index.duplicated()].unique().tolist()\n",
    "        raise ValueError(f\"Duplicate regions found: {dupes}\")\n",
    "\n",
    "    if list(df.columns) != [\"2001\", \"2000\"]:\n",
    "        raise ValueError(f\"Unexpected columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Non-negative check ignoring NaNs\n",
    "    numeric = df[[\"2001\", \"2000\"]]\n",
    "    if (numeric.dropna().lt(0)).any().any():\n",
    "        bad_rows = numeric.dropna().lt(0).any(axis=1)\n",
    "        raise ValueError(f\"Negative values found in rows: {numeric.index[bad_rows].tolist()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df_loaded = load_population_csv(csv_text)\n",
    "display(df_loaded)\n",
    "assert df_loaded.equals(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 — Chunked reading (simulate large CSV)\n",
    "\n",
    "**Task**\n",
    "Pretend the CSV is too large to load at once.\n",
    "\n",
    "1. Read it in **chunks**.\n",
    "2. For each chunk, compute `growth_pct` safely (as in Problem 2).\n",
    "3. Combine the results into a single Series, indexed by region.\n",
    "\n",
    "**Hint**: `pd.read_csv(..., chunksize=...)` returns an iterator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "North      4.347826\n",
       "South     -1.010101\n",
       "East            NaN\n",
       "West            NaN\n",
       "Central    0.917431\n",
       "Name: growth_pct, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 4\n",
    "chunks = pd.read_csv(\n",
    "    StringIO(csv_text),\n",
    "    header=0,\n",
    "    usecols=[0, 1, 2],\n",
    "    names=[\"region\", \"2001\", \"2000\"],\n",
    "    index_col=0,\n",
    "    skipinitialspace=True,\n",
    "    na_values=[\"N/A\", \"NA\", \"\"],\n",
    "    chunksize=2,\n",
    ")\n",
    "\n",
    "parts = []\n",
    "for chunk in chunks:\n",
    "    chunk[\"2001\"] = pd.to_numeric(chunk[\"2001\"], errors=\"coerce\")\n",
    "    chunk[\"2000\"] = pd.to_numeric(chunk[\"2000\"], errors=\"coerce\")\n",
    "    den = chunk[\"2000\"].where(chunk[\"2000\"] != 0)\n",
    "    growth = 100 * (chunk[\"2001\"] - chunk[\"2000\"]) / den\n",
    "    parts.append(growth)\n",
    "\n",
    "growth_pct_chunked = pd.concat(parts).rename(\"growth_pct\")\n",
    "display(growth_pct_chunked)\n",
    "\n",
    "# Check it matches the non-chunked result\n",
    "assert growth_pct_chunked.sort_index().equals(growth_pct.sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 — Load Excel sheet, join with metadata, parse dates\n",
    "\n",
    "**Task**\n",
    "From the in-memory Excel workbook (`excel_bytes`):\n",
    "1. Load sheet `data` with `region` as the index.\n",
    "2. Load sheet `metadata` and parse `opened` as dates.\n",
    "3. Join them into one DataFrame on `region`.\n",
    "4. Compute a new column `age_days` = (today - opened).days.\n",
    "\n",
    "**Expected outcome**\n",
    "- `opened` is datetime64.\n",
    "- Joined DataFrame has columns: `2001`, `2000`, `status`, `manager`, `opened`, `age_days`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2000</th>\n",
       "      <th>status</th>\n",
       "      <th>manager</th>\n",
       "      <th>opened</th>\n",
       "      <th>age_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1150</td>\n",
       "      <td>ok</td>\n",
       "      <td>Ava</td>\n",
       "      <td>2000-01-15</td>\n",
       "      <td>9481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>980.0</td>\n",
       "      <td>990</td>\n",
       "      <td>revised</td>\n",
       "      <td>Noah</td>\n",
       "      <td>1998-07-01</td>\n",
       "      <td>10044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1050</td>\n",
       "      <td>ok</td>\n",
       "      <td>Mia</td>\n",
       "      <td>2001-03-20</td>\n",
       "      <td>9051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ok</td>\n",
       "      <td>Liam</td>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1090</td>\n",
       "      <td>ok</td>\n",
       "      <td>Ema</td>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>9314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2001  2000   status manager     opened  age_days\n",
       "region                                                     \n",
       "North    1200.0  1150       ok     Ava 2000-01-15      9481\n",
       "South     980.0   990  revised    Noah 1998-07-01     10044\n",
       "East        NaN  1050       ok     Mia 2001-03-20      9051\n",
       "West     1500.0     0       ok    Liam 1999-11-05      9552\n",
       "Central  1100.0  1090       ok     Ema 2000-06-30      9314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 5\n",
    "excel_bytes.seek(0)\n",
    "data_df = pd.read_excel(excel_bytes, sheet_name=\"data\", index_col=\"region\")\n",
    "\n",
    "excel_bytes.seek(0)\n",
    "meta_df = pd.read_excel(excel_bytes, sheet_name=\"metadata\")\n",
    "meta_df[\"opened\"] = pd.to_datetime(meta_df[\"opened\"], errors=\"coerce\")\n",
    "meta_df = meta_df.set_index(\"region\")\n",
    "\n",
    "joined = data_df.join(meta_df, how=\"left\")\n",
    "\n",
    "today = pd.Timestamp.today().normalize()\n",
    "joined[\"age_days\"] = (today - joined[\"opened\"]).dt.days\n",
    "\n",
    "display(joined)\n",
    "\n",
    "assert np.issubdtype(joined[\"opened\"].dtype, np.datetime64)\n",
    "expected_cols = {\"2001\", \"2000\", \"status\", \"manager\", \"opened\", \"age_days\"}\n",
    "assert set(joined.columns) == expected_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6 — Enforce dtypes and handle missingness consistently (Excel)\n",
    "\n",
    "**Task**\n",
    "Create a function `load_population_excel(b: BytesIO) -> pd.DataFrame` that:\n",
    "- Loads sheet `data`.\n",
    "- Ensures `2000` and `2001` are numeric.\n",
    "- Treats missing values in `2001` as NaN.\n",
    "- Sets index to `region`.\n",
    "- Returns only columns `2001`, `2000`.\n",
    "\n",
    "**Bonus**: fail fast if any `2000` value is negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>North</th>\n",
       "      <td>1200.0</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>980.0</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>1100.0</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2001  2000\n",
       "region               \n",
       "North    1200.0  1150\n",
       "South     980.0   990\n",
       "East        NaN  1050\n",
       "West     1500.0     0\n",
       "Central  1100.0  1090"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION 6\n",
    "def load_population_excel(b: BytesIO) -> pd.DataFrame:\n",
    "    b.seek(0)\n",
    "    df = pd.read_excel(b, sheet_name=\"data\")\n",
    "\n",
    "    # Normalize column names defensively\n",
    "    expected = {\"region\", \"2001\", \"2000\"}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing expected columns: {sorted(missing)}\")\n",
    "\n",
    "    df = df.set_index(\"region\")\n",
    "    df = df[[\"2001\", \"2000\"]].copy()\n",
    "\n",
    "    df[\"2001\"] = pd.to_numeric(df[\"2001\"], errors=\"coerce\")\n",
    "    df[\"2000\"] = pd.to_numeric(df[\"2000\"], errors=\"coerce\")\n",
    "\n",
    "    # Fail fast if negative baseline exists\n",
    "    if (df[\"2000\"].dropna() < 0).any():\n",
    "        bad = df.index[df[\"2000\"] < 0].tolist()\n",
    "        raise ValueError(f\"Negative 2000 values for regions: {bad}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df_excel = load_population_excel(excel_bytes)\n",
    "display(df_excel)\n",
    "\n",
    "assert df_excel.index.name == \"region\"\n",
    "assert set(df_excel.columns) == {\"2001\", \"2000\"}\n",
    "assert df_excel[[\"2001\", \"2000\"]].dtypes.apply(lambda x: np.issubdtype(x, np.number)).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Recap\n",
    "\n",
    "You practiced:\n",
    "- `read_csv` best practices: `usecols`, `names`, `index_col`, `na_values`, numeric coercion.\n",
    "- Safe arithmetic with missing data and division by zero.\n",
    "- Defensive loader functions with schema + value validation.\n",
    "- Chunked reading with `chunksize`.\n",
    "- `read_excel` with multi-sheet workflows and joining metadata.\n",
    "- Enforcing dtypes and fail-fast checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
