{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sustainable-listening",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-romance",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-audience",
   "metadata": {},
   "source": [
    "Alongside this note book, four CSV files are specified (one is in fact a TSV file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-greensboro",
   "metadata": {},
   "source": [
    "For each file, load it using the CSV module, and find the smallest and largest numbers in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-pathology",
   "metadata": {},
   "source": [
    "All these files contain just lists of numbers - with the exception of a possible header row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1-solution-explained",
   "metadata": {},
   "source": [
    "#### Question 1 – Solution\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Use the built-in **`csv`** module (as required).\n",
    "2. Use **`pathlib.Path`** to locate all `.csv` and `.tsv` files in the current directory.\n",
    "3. For each file:\n",
    "   * Select the correct delimiter based on the extension (`','` for CSV, `'\\t'` for TSV).\n",
    "   * Read all cells and try to convert them to `float`.\n",
    "   * Ignore non-numeric values automatically (this skips header rows and any stray text).\n",
    "   * Track the **minimum** and **maximum** values in a numerically safe way.\n",
    "4. Collect the results in a dictionary `{filename: (min_value, max_value)}` and print them.\n",
    "\n",
    "This approach is robust, handles possible header rows and multiple columns, and keeps the logic well-structured in reusable functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "q1-solution-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file4.csv: No numeric data found in file4.csv\n",
      "Skipping test.csv: No numeric data found in test.csv\n",
      "file1.csv: min = 10.0, max = 80.0\n",
      "file2.csv: min = -3.3, max = 500.0\n",
      "file3.tsv: min = 10.0, max = 300.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from typing import Iterable, Tuple, Dict\n",
    "\n",
    "\n",
    "def _detect_delimiter(path: Path) -> str:\n",
    "    \"\"\"Return the appropriate delimiter for a given file based on its suffix.\n",
    "\n",
    "    *.csv -> ','\n",
    "    *.tsv -> '\\t'\n",
    "    otherwise defaults to ','\n",
    "    \"\"\"\n",
    "    suffix = path.suffix.lower()\n",
    "    if suffix == \".tsv\":\n",
    "        return \"\\t\"\n",
    "    return \",\"\n",
    "\n",
    "\n",
    "def _iter_numeric_values(reader: Iterable[Iterable[str]]) -> Iterable[float]:\n",
    "    \"\"\"Yield numeric values (as floats) from a CSV reader.\n",
    "\n",
    "    Any cell that cannot be converted to float is ignored. This naturally skips\n",
    "    header rows and any non-numeric junk in the file.\n",
    "    \"\"\"\n",
    "    for row in reader:\n",
    "        for cell in row:\n",
    "            text = cell.strip()\n",
    "            if not text:\n",
    "                # Skip empty cells\n",
    "                continue\n",
    "            try:\n",
    "                yield float(text)\n",
    "            except ValueError:\n",
    "                # Non-numeric (e.g., header names) -> just ignore\n",
    "                continue\n",
    "\n",
    "\n",
    "def find_min_max_in_file(path: Path) -> Tuple[float, float]:\n",
    "    \"\"\"Return (min_value, max_value) for all numeric cells in a CSV/TSV file.\n",
    "\n",
    "    Raises ValueError if the file does not contain any numeric values.\n",
    "    \"\"\"\n",
    "    delimiter = _detect_delimiter(path)\n",
    "\n",
    "    with path.open(mode=\"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.reader(f, delimiter=delimiter)\n",
    "        values_iter = _iter_numeric_values(reader)\n",
    "\n",
    "        try:\n",
    "            first_value = next(values_iter)\n",
    "        except StopIteration as exc:\n",
    "            raise ValueError(f\"No numeric data found in {path}\") from exc\n",
    "\n",
    "        # Initialize min and max with the first numeric value\n",
    "        min_value = max_value = first_value\n",
    "\n",
    "        for value in values_iter:\n",
    "            if value < min_value:\n",
    "                min_value = value\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "\n",
    "    return min_value, max_value\n",
    "\n",
    "\n",
    "def find_min_max_for_all_data_files(root: Path | str = Path(\".\")) -> Dict[str, Tuple[float, float]]:\n",
    "    \"\"\"Find min and max values for all CSV/TSV files in the given directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root:\n",
    "        Directory to search for data files. Defaults to current directory.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, Tuple[float, float]]\n",
    "        A mapping from file name to a tuple of (min_value, max_value).\n",
    "    \"\"\"\n",
    "    root_path = Path(root)\n",
    "\n",
    "    data_files = sorted(root_path.glob(\"*.csv\")) + sorted(root_path.glob(\"*.tsv\"))\n",
    "\n",
    "    results: Dict[str, Tuple[float, float]] = {}\n",
    "    for path in data_files:\n",
    "        try:\n",
    "            min_value, max_value = find_min_max_in_file(path)\n",
    "        except ValueError as exc:\n",
    "            # If a file has no numeric data, we report and skip it.\n",
    "            print(f\"Skipping {path.name}: {exc}\")\n",
    "            continue\n",
    "        results[path.name] = (min_value, max_value)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage (run this cell once the data files are in the same directory):\n",
    "results = find_min_max_for_all_data_files()\n",
    "for filename, (min_val, max_val) in results.items():\n",
    "    print(f\"{filename}: min = {min_val}, max = {max_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-anime",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-hunter",
   "metadata": {},
   "source": [
    "Given this data structure consisting of a list of dictionaries, write a function that will write this data out to a file, where the column headers (in the first row) are based on the dictionary keys, and the values are flattened out to one row per dictionary (under the corresponding column header)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-flower",
   "metadata": {},
   "source": [
    "Note that not all dictionaries contain all the same keys, nor are the keys necessarily in the same order when present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-sussex",
   "metadata": {},
   "source": [
    "For \"missing\" values, your function should just write an empty string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-cheese",
   "metadata": {},
   "source": [
    "For example, given this `data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorporate-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'a': '1_a', 'b': '1_b', 'c': '1_c'},\n",
    "    {'c': '2_c', 'd': '2_d'},\n",
    "    {'a': '3_a', 'c': '3_c', 'e': '3_e'}\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "olive-alcohol",
   "metadata": {},
   "source": [
    "Your output file should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-aside",
   "metadata": {},
   "source": [
    "```\n",
    "a,b,c,d,e\n",
    "1_a,1_b,1_c,,,\n",
    ",,2_c,2_d,\n",
    "3_a,,3_c,,3_e\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-engine",
   "metadata": {},
   "source": [
    "The order of the columns and rows is not important - as long as they match up with respective column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2-solution-explained",
   "metadata": {},
   "source": [
    "#### Question 2 – Solution\n",
    "\n",
    "We want a reusable function that:\n",
    "\n",
    "1. Accepts a **list of dictionaries** and an **output file path**.\n",
    "2. Computes the **union of all keys** across all dictionaries.\n",
    "3. Writes those keys as the **header row**.\n",
    "4. Writes one row per dictionary. For keys that are missing in a particular dictionary, an **empty string** should appear in the CSV.\n",
    "\n",
    "We can do this cleanly with `csv.DictWriter`:\n",
    "\n",
    "* `fieldnames` will be the sorted union of all keys.\n",
    "* Writing each dictionary with `writer.writerow(row)` automatically fills missing keys with empty strings.\n",
    "* We add simple validation so an empty data list is handled explicitly.\n",
    "\n",
    "Below is a best-practice implementation plus a small demo using the provided `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "q2-solution-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote CSV to: D:\\_Udemy_course_PRACTICE\\Python_3_Fundamentals_Udemy_by_Fred_Baptiste\\22_CSV_Module\\06_Exercises\\output.csv\n",
      "\n",
      "File contents:\n",
      "----------------\n",
      "a,b,c,d,e\n",
      "1_a,1_b,1_c,,\n",
      ",,2_c,2_d,\n",
      "3_a,,3_c,,3_e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "from typing import Iterable, Mapping, Any, List\n",
    "\n",
    "\n",
    "def write_dicts_to_csv(\n",
    "    rows: Iterable[Mapping[str, Any]],\n",
    "    output_path: Path | str,\n",
    ") -> None:\n",
    "    \"\"\"Write a list of dictionaries to a CSV file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rows:\n",
    "        An iterable of dictionaries. Keys will become column headers.\n",
    "    output_path:\n",
    "        File path to write the CSV to.\n",
    "\n",
    "    Behaviour\n",
    "    ---------\n",
    "    * The set of headers is the union of all keys across all dictionaries.\n",
    "    * Missing keys for a particular row are written as empty strings.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_path)\n",
    "\n",
    "    # Materialize the rows so we can iterate multiple times safely\n",
    "    row_list: List[Mapping[str, Any]] = list(rows)\n",
    "\n",
    "    if not row_list:\n",
    "        raise ValueError(\"Cannot write CSV: no data rows provided.\")\n",
    "\n",
    "    # Collect union of all keys\n",
    "    all_keys = set()\n",
    "    for row in row_list:\n",
    "        all_keys.update(row.keys())\n",
    "\n",
    "    # Sort keys to make the output deterministic and easy to test\n",
    "    fieldnames = sorted(all_keys)\n",
    "\n",
    "    with output_path.open(mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction=\"ignore\")\n",
    "        writer.writeheader()\n",
    "        for row in row_list:\n",
    "            # DictWriter will automatically fill missing keys with ''\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n",
    "# --- Demo using the provided `data` structure ---\n",
    "data = [\n",
    "    {\"a\": \"1_a\", \"b\": \"1_b\", \"c\": \"1_c\"},\n",
    "    {\"c\": \"2_c\", \"d\": \"2_d\"},\n",
    "    {\"a\": \"3_a\", \"c\": \"3_c\", \"e\": \"3_e\"},\n",
    "]\n",
    "\n",
    "output_file = Path(\"output.csv\")\n",
    "write_dicts_to_csv(data, output_file)\n",
    "\n",
    "print(f\"Wrote CSV to: {output_file.resolve()}\")\n",
    "print(\"\\nFile contents:\\n----------------\")\n",
    "print(output_file.read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9daf6c-4d7d-4061-81d7-438c0e358778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
