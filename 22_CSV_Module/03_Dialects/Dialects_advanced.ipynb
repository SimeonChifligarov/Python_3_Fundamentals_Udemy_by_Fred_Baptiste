{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aacc22e",
   "metadata": {},
   "source": [
    "## Advanced Exercises - CSV Dialects in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ec8bb",
   "metadata": {},
   "source": [
    "These exercises assume you already know how to use `csv.reader`, `csv.writer`, and how to register custom dialects.\n",
    "\n",
    "Each exercise comes with a reference solution implemented in Python. Read the exercise description first, then try to solve it before looking at the solution code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ca97a",
   "metadata": {},
   "source": [
    "### Exercise 1 - Detect and use a dialect automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bbe97d",
   "metadata": {},
   "source": [
    "You are given CSV data where the delimiter and quoting style are not known ahead of time.\n",
    "\n",
    "1. Use `csv.Sniffer` to detect the dialect from a sample of the data.\n",
    "2. Reset the stream and read all rows using the detected dialect.\n",
    "3. Print the rows and assert that the header has the expected column names.\n",
    "\n",
    "Hint: wrap the raw text in an `io.StringIO` object so you can treat it like a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef20282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected delimiter: ';'\n",
      "Detected quotechar: \"'\"\n",
      "['name', 'age', 'city']\n",
      "['John Doe', '31', '\"New York\"']\n",
      "['Jane Smith', '29', '\"San Francisco\"']\n",
      "['Foo Bar', '40', '\"London\"']\n",
      "\n",
      "Exercise 1: header assertion passed.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "import textwrap\n",
    "\n",
    "raw_data = textwrap.dedent(\"\"\"\\\n",
    "name;age;city\n",
    "'John Doe';31;\"New York\"\n",
    "'Jane Smith';29;\"San Francisco\"\n",
    "'Foo Bar';40;\"London\"\n",
    "\"\"\")\n",
    "\n",
    "buffer = io.StringIO(raw_data)\n",
    "\n",
    "sample = buffer.read(200)\n",
    "buffer.seek(0)\n",
    "\n",
    "sniffer = csv.Sniffer()\n",
    "detected_dialect = sniffer.sniff(sample)\n",
    "\n",
    "print(f\"Detected delimiter: {detected_dialect.delimiter!r}\")\n",
    "print(f\"Detected quotechar: {detected_dialect.quotechar!r}\")\n",
    "\n",
    "reader = csv.reader(buffer, dialect=detected_dialect)\n",
    "rows = list(reader)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "header = rows[0]\n",
    "assert header == ['name', 'age', 'city'], f\"Unexpected header: {header!r}\"\n",
    "\n",
    "print(\"\\nExercise 1: header assertion passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e2c3b",
   "metadata": {},
   "source": [
    "### Exercise 2 - Define and reuse a custom dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a20205",
   "metadata": {},
   "source": [
    "You receive log-like data files with the following properties:\n",
    "\n",
    "- Fields are separated by a vertical bar (`|`).\n",
    "- Fields may be surrounded by double quotes.\n",
    "- Inside quoted fields, double quotes are escaped by doubling them (`\"\"`).\n",
    "- Leading spaces after the delimiter should be ignored.\n",
    "\n",
    "1. Register a dialect named `logpipe` that captures this format.\n",
    "2. Use that dialect to read the rows into a list of dictionaries using `csv.DictReader`.\n",
    "3. Assert that the list has 3 records and that the last record has `level == 'ERROR'`.\n",
    "\n",
    "Best practice: register dialects once near the start of your program or module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b581919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level': 'INFO  ', 'message': 'Started worker           ', 'module': 'core'}\n",
      "{'level': 'WARNING ', 'message': 'High latency (\"db\") ', 'module': 'network'}\n",
      "{'level': 'ERROR ', 'message': 'Failed to connect       ', 'module': 'network'}\n",
      "\n",
      "Exercise 2: assertions passed.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "import textwrap\n",
    "\n",
    "raw_logs = textwrap.dedent(\"\"\"\\\n",
    "level | message                    | module\n",
    "INFO  | \"Started worker\"           | core\n",
    "WARNING | \"High latency (\"\"db\"\")\" | network\n",
    "ERROR | \"Failed to connect\"       | network\n",
    "\"\"\")\n",
    "\n",
    "csv.register_dialect(\n",
    "    'logpipe',\n",
    "    delimiter='|',\n",
    "    quotechar='\"',\n",
    "    doublequote=True,\n",
    "    skipinitialspace=True\n",
    ")\n",
    "\n",
    "buffer = io.StringIO(raw_logs)\n",
    "\n",
    "reader = csv.DictReader(buffer, dialect='logpipe')\n",
    "\n",
    "# FIX: strip header names\n",
    "reader.fieldnames = [name.strip() for name in reader.fieldnames]\n",
    "\n",
    "records = list(reader)\n",
    "\n",
    "for record in records:\n",
    "    print(record)\n",
    "\n",
    "assert len(records) == 3, f\"Expected 3 records, got {len(records)}\"\n",
    "assert records[-1][\"level\"].strip() == \"ERROR\", \"Last record is not ERROR\"\n",
    "\n",
    "print(\"\\nExercise 2: assertions passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ea1fd",
   "metadata": {},
   "source": [
    "### Exercise 3 - Round-tripping data with a dialect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e3640c",
   "metadata": {},
   "source": [
    "Suppose you want to ensure that when you write CSV data and then read it back with the same dialect, your data structure is preserved.\n",
    "\n",
    "1. Register a dialect `semicolon_backslash` with these rules:\n",
    "   - Delimiter: `;`\n",
    "   - Quote character: `\"`\n",
    "   - Escape character: `\\\\`\n",
    "   - `quoting=csv.QUOTE_MINIMAL`\n",
    "2. Given a list of rows (as lists of strings), write them to an in-memory buffer using `csv.writer`.\n",
    "3. Reset the buffer and read the data back using `csv.reader` and the same dialect.\n",
    "4. Assert that the original and the round-tripped rows are exactly the same.\n",
    "\n",
    "Hint: use `io.StringIO` to avoid touching the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779ad5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written and read back rows:\n",
      "['id', 'name', 'comment']\n",
      "['1', 'Alice', 'Loves \"Python\"; uses\\\\scripts']\n",
      "['2', 'Bob', 'Enjoys data; hates \"bugs\"']\n",
      "\n",
      "Exercise 3: round-trip assertion passed.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "\n",
    "csv.register_dialect(\n",
    "    'semicolon_backslash',\n",
    "    delimiter=';',\n",
    "    quotechar='\"',\n",
    "    escapechar='\\\\',\n",
    "    quoting=csv.QUOTE_MINIMAL\n",
    ")\n",
    "\n",
    "original_rows = [\n",
    "    ['id', 'name', 'comment'],\n",
    "    ['1', 'Alice', 'Loves \"Python\"; uses\\\\scripts'],\n",
    "    ['2', 'Bob', 'Enjoys data; hates \"bugs\"']\n",
    "]\n",
    "\n",
    "buffer = io.StringIO()\n",
    "writer = csv.writer(buffer, dialect='semicolon_backslash')\n",
    "writer.writerows(original_rows)\n",
    "\n",
    "buffer.seek(0)\n",
    "\n",
    "reader = csv.reader(buffer, dialect='semicolon_backslash')\n",
    "round_tripped_rows = list(reader)\n",
    "\n",
    "print(\"Written and read back rows:\")\n",
    "for row in round_tripped_rows:\n",
    "    print(row)\n",
    "\n",
    "assert round_tripped_rows == original_rows, \"Round-tripped rows do not match the original!\"\n",
    "\n",
    "print(\"\\nExercise 3: round-trip assertion passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb866fa",
   "metadata": {},
   "source": [
    "### Exercise 4 - Context manager for temporary dialects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515314ab",
   "metadata": {},
   "source": [
    "Sometimes you want to temporarily register a dialect for a small block of code, and then automatically clean it up so it does not pollute the global registry.\n",
    "\n",
    "1. Implement a context manager `temporary_dialect(name, **params)` that:\n",
    "   - Registers a dialect with the given `name` and parameters on entry.\n",
    "   - Remembers whether a dialect with that name already existed.\n",
    "   - Restores the previous dialect (if any) or unregisters the new one on exit.\n",
    "2. Use the context manager to read a small in-memory CSV with a custom delimiter.\n",
    "3. After the `with` block, assert that either the old dialect is back or that the new one is no longer registered.\n",
    "\n",
    "Hint: use `contextlib.contextmanager` and `csv.list_dialects()` / `csv.get_dialect()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7cb8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows read with temporary dialect:\n",
      "[]\n",
      "['a', 'b', 'c']\n",
      "['1', '2', '3']\n",
      "['4', '5', '6']\n",
      "\n",
      "Exercise 4: dialect registry restored correctly.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "import textwrap\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def temporary_dialect(name: str, **params):\n",
    "    dialect_existed = name in csv.list_dialects()\n",
    "    old_dialect = csv.get_dialect(name) if dialect_existed else None\n",
    "\n",
    "    csv.register_dialect(name, **params)\n",
    "\n",
    "    try:\n",
    "        yield csv.get_dialect(name)\n",
    "    finally:\n",
    "        if dialect_existed:\n",
    "            csv.unregister_dialect(name)\n",
    "            csv.register_dialect(name, old_dialect)\n",
    "        else:\n",
    "            csv.unregister_dialect(name)\n",
    "\n",
    "raw_data = textwrap.dedent(\"\"\"\\n    a|b|c\n",
    "    1|2|3\n",
    "    4|5|6\n",
    "\"\"\")\n",
    "\n",
    "before = set(csv.list_dialects())\n",
    "\n",
    "with temporary_dialect('temp_pipe', delimiter='|'):\n",
    "    buffer = io.StringIO(raw_data)\n",
    "    reader = csv.reader(buffer, dialect='temp_pipe')\n",
    "    rows = list(reader)\n",
    "    print(\"Rows read with temporary dialect:\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "\n",
    "after = set(csv.list_dialects())\n",
    "\n",
    "assert before == after, \"Dialect registry changed after using temporary_dialect!\"\n",
    "\n",
    "print(\"\\nExercise 4: dialect registry restored correctly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146919e",
   "metadata": {},
   "source": [
    "---\n",
    "All exercises above are self-contained and use only in-memory text. You can experiment by modifying the dialect parameters and observing how the parsing changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c760103-4b89-4825-8f8e-f2f613c69319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
