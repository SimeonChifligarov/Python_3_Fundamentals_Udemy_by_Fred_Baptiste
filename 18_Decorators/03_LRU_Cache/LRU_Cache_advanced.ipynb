{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LRU Cache & Decorators â€“ Practice Notebook\n",
    "\n",
    "This notebook contains a series of **advanced (but not too advanced)** practice problems \n",
    "around **decorators**, **memoization**, and **LRU caches**.\n",
    "\n",
    "Each exercise has:\n",
    "\n",
    "- A description in a markdown cell\n",
    "- A starter code cell (now fully implemented) \n",
    "\n",
    "You can run cells, experiment, and modify the implementations if you want to explore further. \n",
    "All TODOs have been implemented for you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 â€“ Simple memoization decorator (positional args only)\n",
    "\n",
    "Write a decorator `memoize_positional` that:\n",
    "\n",
    "- Caches results **based only on positional arguments** (`*args`)\n",
    "- Uses a simple dictionary as the cache\n",
    "- Prints `\"cache hit\"` when a cached value is returned\n",
    "- Does **not** support keyword-only arguments (it's OK to ignore `**kwargs` for this one)\n",
    "\n",
    "Then:\n",
    "\n",
    "1. Decorate the function `slow_add(a, b)` that:\n",
    "   - Prints `f\"computing slow_add({a}, {b})\"` when called\n",
    "   - Returns `a + b`\n",
    "2. Call `slow_add(10, 20)` three times and verify:\n",
    "   - The message is printed **only once**\n",
    "   - Subsequent calls print `\"cache hit\"` instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing slow_add(10, 20)\n",
      "cache hit\n",
      "cache hit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def memoize_positional(func):\n",
    "    \"\"\"Simple memoization decorator that only supports positional args.\n",
    "\n",
    "    Caches results based on the tuple of positional arguments.\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "\n",
    "    @wraps(func)\n",
    "    def inner(*args):\n",
    "        key = args\n",
    "        if key in cache:\n",
    "            print(\"cache hit\")\n",
    "            return cache[key]\n",
    "        result = func(*args)\n",
    "        cache[key] = result\n",
    "        return result\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "@memoize_positional\n",
    "def slow_add(a, b):\n",
    "    print(f\"computing slow_add({a}, {b})\")\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# Try these calls:\n",
    "slow_add(10, 20)\n",
    "slow_add(10, 20)\n",
    "slow_add(10, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 â€“ Supporting both `*args` and `**kwargs`\n",
    "\n",
    "Extend the idea from Exercise 1 to support **both positional and keyword arguments**.\n",
    "\n",
    "Write a decorator `memoize` that:\n",
    "\n",
    "- Accepts any combination of `*args` and `**kwargs`\n",
    "- Builds a **hashable** cache key from:\n",
    "  - The tuple of `args`\n",
    "  - A `frozenset` of `kwargs.items()` (sorted or not â€“ `frozenset` is fine)\n",
    "- Prints:\n",
    "  - `\"cache miss\"` when computing & storing a new value\n",
    "  - `\"cache hit\"` when reusing a cached value\n",
    "\n",
    "Then:\n",
    "\n",
    "1. Decorate the function:\n",
    "\n",
    "   ```python\n",
    "   def power(base, exp=2):\n",
    "       return base ** exp\n",
    "   ```\n",
    "\n",
    "2. Test that the following calls use the cache correctly:\n",
    "\n",
    "   ```python\n",
    "   power(2)\n",
    "   power(2)\n",
    "   power(2, exp=3)\n",
    "   power(2, exp=3)\n",
    "   power(base=2, exp=3)\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache miss\n",
      "cache hit\n",
      "cache miss\n",
      "cache hit\n",
      "cache miss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def memoize(func):\n",
    "    \"\"\"Memoization decorator that caches based on both args and kwargs.\n",
    "\n",
    "    The cache key is a tuple: (args, frozenset(kwargs.items())).\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "\n",
    "    @wraps(func)\n",
    "    def inner(*args, **kwargs):\n",
    "        key = (args, frozenset(kwargs.items()))\n",
    "        if key in cache:\n",
    "            print(\"cache hit\")\n",
    "            return cache[key]\n",
    "        print(\"cache miss\")\n",
    "        result = func(*args, **kwargs)\n",
    "        cache[key] = result\n",
    "        return result\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "@memoize\n",
    "def power(base, exp=2):\n",
    "    return base ** exp\n",
    "\n",
    "\n",
    "# Try:\n",
    "power(2)\n",
    "power(2)\n",
    "power(2, exp=3)\n",
    "power(2, exp=3)\n",
    "power(base=2, exp=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 â€“ LRU cache with a fixed max size\n",
    "\n",
    "Implement a **very small** LRU cache decorator `tiny_lru(maxsize)` using `collections.OrderedDict`.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- `tiny_lru` is a **decorator factory**:\n",
    "  - Called as `@tiny_lru(maxsize=3)`\n",
    "- Internally uses an `OrderedDict` that:\n",
    "  - Stores keys in order of **recent use**\n",
    "  - On each successful cache hit, moves the key to the *end* (most recently used)\n",
    "  - When inserting a new key:\n",
    "    - If the cache size would exceed `maxsize`, evicts the **least recently used** item\n",
    "- For debugging, prints:\n",
    "  - `\"cache hit for {key}\"`\n",
    "  - `\"cache miss for {key}\"`\n",
    "  - `\"evicting {old_key}\"` when an item is discarded\n",
    "\n",
    "Then decorate:\n",
    "\n",
    "```python\n",
    "def mul(a, b):\n",
    "    print(f\"computing mul({a}, {b})\")\n",
    "    return a * b\n",
    "```\n",
    "\n",
    "with `@tiny_lru(maxsize=2)` and study the behavior for these calls:\n",
    "\n",
    "```python\n",
    "mul(1, 2)   # miss\n",
    "mul(1, 2)   # hit\n",
    "mul(2, 2)   # miss\n",
    "mul(3, 3)   # miss, should evict the least recently used key\n",
    "mul(1, 2)   # might be a miss again depending on eviction\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache miss for (1, 2)\n",
      "computing mul(1, 2)\n",
      "cache hit for (1, 2)\n",
      "cache miss for (2, 2)\n",
      "computing mul(2, 2)\n",
      "cache miss for (3, 3)\n",
      "computing mul(3, 3)\n",
      "evicting (1, 2)\n",
      "cache miss for (1, 2)\n",
      "computing mul(1, 2)\n",
      "evicting (2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def tiny_lru(maxsize=128):\n",
    "    \"\"\"Very small LRU cache using OrderedDict.\n",
    "\n",
    "    Only supports positional arguments for simplicity.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        cache = OrderedDict()\n",
    "\n",
    "        @wraps(func)\n",
    "        def inner(*args):\n",
    "            key = args\n",
    "            if key in cache:\n",
    "                print(f\"cache hit for {key}\")\n",
    "                # mark as recently used\n",
    "                cache.move_to_end(key)\n",
    "                return cache[key]\n",
    "\n",
    "            print(f\"cache miss for {key}\")\n",
    "            result = func(*args)\n",
    "            cache[key] = result\n",
    "            cache.move_to_end(key)\n",
    "\n",
    "            if len(cache) > maxsize:\n",
    "                old_key, _ = cache.popitem(last=False)\n",
    "                print(f\"evicting {old_key}\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        return inner\n",
    "\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@tiny_lru(maxsize=2)\n",
    "def mul(a, b):\n",
    "    print(f\"computing mul({a}, {b})\")\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Try:\n",
    "mul(1, 2)\n",
    "mul(1, 2)\n",
    "mul(2, 2)\n",
    "mul(3, 3)\n",
    "mul(1, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 â€“ Combining logging and caching decorators\n",
    "\n",
    "You are given two decorators:\n",
    "\n",
    "- `log_calls` â€“ logs function name and arguments\n",
    "- `memoize` â€“ from Exercise 2\n",
    "\n",
    "### Part A\n",
    "\n",
    "Implement `log_calls(func)` that:\n",
    "\n",
    "- Prints a message **before** calling the function:\n",
    "\n",
    "  ```text\n",
    "  calling <name> with args=<args>, kwargs=<kwargs>\n",
    "  ```\n",
    "\n",
    "- Prints a message **after** the call:\n",
    "\n",
    "  ```text\n",
    "  <name> returned <result>\n",
    "  ```\n",
    "\n",
    "### Part B\n",
    "\n",
    "Decorate the function `fib(n)` (naive recursive Fibonacci) in two different ways:\n",
    "\n",
    "1. `@log_calls` then `@memoize` (i.e., `@memoize` is the *outer* decorator)\n",
    "2. `@memoize` then `@log_calls`\n",
    "\n",
    "And observe:\n",
    "\n",
    "- How many log lines do you see for computing, say, `fib(10)`?\n",
    "- What's the difference between the two decorator orders?\n",
    "\n",
    "> ðŸ’¡ This exercise is designed to help you understand how *decorator order* affects behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_calls(func):\n",
    "    \"\"\"Decorator that logs function calls and return values.\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def inner(*args, **kwargs):\n",
    "        print(f\"calling {func.__name__} with args={args}, kwargs={kwargs}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__} returned {result}\")\n",
    "        return result\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "# Option 1: memoize outside, log inside\n",
    "# Uncomment to experiment after reading the output\n",
    "#\n",
    "@memoize\n",
    "@log_calls\n",
    "def fib_logged_then_cached(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_logged_then_cached(n-1) + fib_logged_then_cached(n-2)\n",
    "\n",
    "\n",
    "# Option 2: log outside, memoize inside\n",
    "#\n",
    "@log_calls\n",
    "@memoize\n",
    "def fib_cached_then_logged(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_cached_then_logged(n-1) + fib_cached_then_logged(n-2)\n",
    "\n",
    "\n",
    "# After uncommenting and defining, try:\n",
    "fib_logged_then_cached(10)\n",
    "fib_cached_then_logged(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 â€“ Measuring speedup with `functools.lru_cache`\n",
    "\n",
    "In this exercise you'll:\n",
    "\n",
    "1. Implement a **naive**, recursive Fibonacci function `fib_plain(n)` (no caching).\n",
    "2. Implement a cached version `fib_cached(n)` using `@functools.lru_cache(maxsize=None)`.\n",
    "3. Use `time.perf_counter()` to measure the time it takes to compute `fib_plain(35)` vs `fib_cached(35)`.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Print the timings like:\n",
    "\n",
    "  ```text\n",
    "  fib_plain(35) took 0.8231 seconds, result=9227465\n",
    "  fib_cached(35) took 0.00001 seconds, result=9227465\n",
    "  ```\n",
    "\n",
    "- Make sure the cached version calls `fib_cached(35)` **twice**:\n",
    "  - First call warms up the cache\n",
    "  - Second call should be almost instantaneous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fib_plain(35) took 1.923673 seconds, result=9227465\n",
      "fib_cached(35) first call took 0.000019 seconds, result=9227465\n",
      "fib_cached(35) second call took 0.000000 seconds, result=9227465\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "from time import perf_counter\n",
    "\n",
    "# naive recursive implementation (no caching)\n",
    "def fib_plain(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_plain(n - 1) + fib_plain(n - 2)\n",
    "\n",
    "\n",
    "# cached implementation using lru_cache\n",
    "@lru_cache(maxsize=None)\n",
    "def fib_cached(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fib_cached(n - 1) + fib_cached(n - 2)\n",
    "\n",
    "\n",
    "def benchmark_fib():\n",
    "    n = 35\n",
    "\n",
    "    # plain version\n",
    "    start = perf_counter()\n",
    "    result_plain = fib_plain(n)\n",
    "    end = perf_counter()\n",
    "    print(f\"fib_plain({n}) took {end - start:.6f} seconds, result={result_plain}\")\n",
    "\n",
    "    # cached version â€“ first call (warms up cache)\n",
    "    start = perf_counter()\n",
    "    result_cached = fib_cached(n)\n",
    "    end = perf_counter()\n",
    "    print(f\"fib_cached({n}) first call took {end - start:.6f} seconds, result={result_cached}\")\n",
    "\n",
    "    # cached version â€“ second call (should be very fast)\n",
    "    start = perf_counter()\n",
    "    result_cached_2 = fib_cached(n)\n",
    "    end = perf_counter()\n",
    "    print(f\"fib_cached({n}) second call took {end - start:.6f} seconds, result={result_cached_2}\")\n",
    "\n",
    "\n",
    "# Run this to compare performance:\n",
    "benchmark_fib()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
