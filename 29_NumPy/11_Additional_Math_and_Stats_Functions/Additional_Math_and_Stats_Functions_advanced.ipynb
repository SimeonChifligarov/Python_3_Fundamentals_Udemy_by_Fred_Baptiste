{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Math and Stats Functions (Advanced)\n",
    "\n",
    "This notebook contains **advanced (but not too much)** NumPy practice problems focused on:\n",
    "\n",
    "- `amin` / `amax` (and `argmin` / `argmax`) with `axis`\n",
    "- `mean` / `median` / `std` and robust statistics\n",
    "- `sum` with axes and sanity checks\n",
    "- rounding with `around`\n",
    "- `histogram` for frequency distributions\n",
    "- practical, vectorized implementations and validation\n",
    "\n",
    "## Best practices used\n",
    "- Reproducibility via random seeds\n",
    "- Clear problem statements + expected behavior\n",
    "- Vectorized solutions (avoid Python loops where reasonable)\n",
    "- Validation with assertions / `np.testing`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "def assert_close(a, b, *, rtol=1e-7, atol=1e-9, err_msg=\"\"):\n",
    "    np.testing.assert_allclose(a, b, rtol=rtol, atol=atol, err_msg=err_msg)\n",
    "\n",
    "def assert_equal(a, b, *, err_msg=\"\"):\n",
    "    np.testing.assert_array_equal(a, b, err_msg=err_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 — Column-wise min/max, and *where* they occur\n",
    "\n",
    "Given the matrix `M`, compute:\n",
    "\n",
    "1. `col_min`: the minimum of each column\n",
    "2. `col_max`: the maximum of each column\n",
    "3. `col_argmin`: the row index of the minimum in each column\n",
    "4. `col_argmax`: the row index of the maximum in each column\n",
    "\n",
    "Then verify:\n",
    "\n",
    "- `M[col_argmin[j], j] == col_min[j]` for each column `j`\n",
    "- `M[col_argmax[j], j] == col_max[j]` for each column `j`\n",
    "\n",
    "**Tip:** use `np.amin/np.amax` and `np.argmin/np.argmax` with `axis=0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0, -1, -3,  1]),\n",
       " array([ 7,  8, 11, 10]),\n",
       " array([2, 3, 1, 0]),\n",
       " array([1, 1, 3, 2]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([\n",
    "    [ 5,  2,  9,  1],\n",
    "    [ 7,  8, -3,  4],\n",
    "    [ 0,  6,  2, 10],\n",
    "    [ 3, -1, 11,  4],\n",
    "])\n",
    "\n",
    "col_min = np.amin(M, axis=0)\n",
    "col_max = np.amax(M, axis=0)\n",
    "col_argmin = np.argmin(M, axis=0)\n",
    "col_argmax = np.argmax(M, axis=0)\n",
    "\n",
    "# Validation (vectorized): pick entries M[row_index_per_col, col_index]\n",
    "cols = np.arange(M.shape[1])\n",
    "assert_equal(M[col_argmin, cols], col_min, err_msg=\"argmin indices do not match col_min\")\n",
    "assert_equal(M[col_argmax, cols], col_max, err_msg=\"argmax indices do not match col_max\")\n",
    "\n",
    "col_min, col_max, col_argmin, col_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 — Normalize rows to percentages (safe division)\n",
    "\n",
    "You are given a nonnegative matrix `X` representing counts per category (columns) for multiple groups (rows).\n",
    "\n",
    "Compute `P`, where each row is converted to **percentages summing to 100**:\n",
    "\n",
    "- `P[i, :] = X[i, :] / sum(X[i, :]) * 100`\n",
    "\n",
    "Edge case: if a row sum is 0, return a row of zeros (avoid NaNs/Infs).\n",
    "\n",
    "Finally, verify:\n",
    "- rows with nonzero sum satisfy `P.sum(axis=1) == 100` (within floating tolerance)\n",
    "- rows with zero sum satisfy `P.sum(axis=1) == 0`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.6667,  0.    , 33.3333],\n",
       "       [ 0.    ,  0.    ,  0.    ],\n",
       "       [20.    , 30.    , 50.    ],\n",
       "       [33.3333, 33.3333, 33.3333]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [10,  0,  5],\n",
    "    [ 0,  0,  0],\n",
    "    [ 2,  3,  5],\n",
    "    [ 1,  1,  1],\n",
    "], dtype=float)\n",
    "\n",
    "row_sums = np.sum(X, axis=1, keepdims=True)\n",
    "\n",
    "# Safe division: only divide where row sum != 0\n",
    "P = np.divide(X, row_sums, out=np.zeros_like(X), where=(row_sums != 0)) * 100\n",
    "\n",
    "sums = P.sum(axis=1)\n",
    "nonzero_rows = (row_sums[:, 0] != 0)\n",
    "zero_rows = ~nonzero_rows\n",
    "\n",
    "assert_close(sums[nonzero_rows], np.full(np.sum(nonzero_rows), 100.0), atol=1e-8)\n",
    "assert_close(sums[zero_rows], np.zeros(np.sum(zero_rows)), atol=1e-8)\n",
    "\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 — Robust z-scores using median and MAD\n",
    "\n",
    "Classic z-scores use mean and standard deviation, but can be sensitive to outliers.\n",
    "\n",
    "Implement a **robust z-score** for a 1D array `x`:\n",
    "\n",
    "- `median = np.median(x)`\n",
    "- `mad = median(|x - median|)`  (MAD: median absolute deviation)\n",
    "- `robust_z = 0.6745 * (x - median) / mad`\n",
    "\n",
    "Edge case: if `mad == 0`, return zeros (avoid division by zero).\n",
    "\n",
    "Compute robust z-scores for `x` below, and verify that the largest outlier has a large absolute robust z-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(11.0),\n",
       " np.float64(1.0),\n",
       " array([ -0.6745,   0.    ,  -0.6745,   0.6745,   0.    ,  -0.6745,\n",
       "        127.4805]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([10, 11, 10, 12, 11, 10, 200], dtype=float)  # 200 is an outlier\n",
    "\n",
    "med = np.median(x)\n",
    "mad = np.median(np.abs(x - med))\n",
    "\n",
    "if mad == 0:\n",
    "    robust_z = np.zeros_like(x)\n",
    "else:\n",
    "    robust_z = 0.6745 * (x - med) / mad\n",
    "\n",
    "# Sanity: outlier should stand out strongly\n",
    "outlier_idx = np.argmax(np.abs(x - med))\n",
    "assert np.abs(robust_z[outlier_idx]) > 10, \"Outlier robust z-score should be large\"\n",
    "\n",
    "med, mad, robust_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 — Weighted average per column + compare to replication trick\n",
    "\n",
    "Given observations (rows) and features (columns) in `A`, and nonnegative weights `w` for each row:\n",
    "\n",
    "1. Compute the **weighted mean per column** using `np.average(A, axis=0, weights=w)`.\n",
    "2. Validate the result by a *replication* approach:\n",
    "   - scale to small integers and repeat rows accordingly, then compute the unweighted mean.\n",
    "\n",
    "Use the provided data where the replication approach is feasible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.3333,  23.3333, 233.3333])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1.0, 10.0, 100.0],\n",
    "    [2.0, 20.0, 200.0],\n",
    "    [3.0, 30.0, 300.0],\n",
    "])\n",
    "w = np.array([1, 2, 3], dtype=float)\n",
    "\n",
    "wmean = np.average(A, axis=0, weights=w)\n",
    "\n",
    "# Replication validation: repeat row i exactly w[i] times (w are small integers here)\n",
    "repeated = np.repeat(A, repeats=w.astype(int), axis=0)\n",
    "mean_rep = np.mean(repeated, axis=0)\n",
    "\n",
    "assert_close(wmean, mean_rep, atol=1e-12)\n",
    "\n",
    "wmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 — Histogram as a discrete probability model\n",
    "\n",
    "Simulate 50,000 dice rolls (values 1–6). Then:\n",
    "\n",
    "1. Build a histogram with bin edges `[1,2,3,4,5,6,7]` so each face is its own bin.\n",
    "2. Convert counts to probabilities.\n",
    "3. Compute the expected value `E[X]` from the histogram:\n",
    "   - `E[X] = sum(face * prob(face))`\n",
    "\n",
    "Verify `E[X]` is close to 3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8340, 8277, 8456, 8405, 8263, 8259]),\n",
       " array([0.1668, 0.1655, 0.1691, 0.1681, 0.1653, 0.1652]),\n",
       " np.float64(3.4950200000000002))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "rolls = rng.integers(1, 7, size=50_000)\n",
    "\n",
    "bin_edges = np.arange(1, 8)  # [1,2,3,4,5,6,7]\n",
    "counts, edges = np.histogram(rolls, bins=bin_edges)\n",
    "\n",
    "probs = counts / counts.sum()\n",
    "faces = edges[:-1]  # 1..6\n",
    "\n",
    "EX = np.sum(faces * probs)\n",
    "assert abs(EX - 3.5) < 0.05, f\"Expected value too far from 3.5: got {EX}\"\n",
    "\n",
    "counts, probs, EX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6 — Rounding strategy: bankers rounding vs always-up cents\n",
    "\n",
    "You are given an array of prices with 3 decimal places. Compute two versions:\n",
    "\n",
    "1. `bankers`: using `np.around(prices, 2)` (NumPy uses round-to-even behavior for ties)\n",
    "2. `always_up`: round *up* to 2 decimals (ceiling at the cent):\n",
    "   - `always_up = np.ceil(prices * 100) / 100`\n",
    "\n",
    "Then compare both arrays.\n",
    "\n",
    "**Goal:** understand that different rounding rules can change totals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.005,  2.675,  3.335, 10.101, 10.1  ]),\n",
       " array([ 1.  ,  2.68,  3.34, 10.1 , 10.1 ]),\n",
       " array([ 1.01,  2.68,  3.34, 10.11, 10.1 ]),\n",
       " np.float64(27.22),\n",
       " np.float64(27.240000000000002))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = np.array([1.005, 2.675, 3.335, 10.101, 10.100], dtype=float)\n",
    "\n",
    "bankers = np.around(prices, 2)\n",
    "always_up = np.ceil(prices * 100) / 100\n",
    "\n",
    "# Compare totals\n",
    "total_bankers = np.sum(bankers)\n",
    "total_always_up = np.sum(always_up)\n",
    "\n",
    "prices, bankers, always_up, total_bankers, total_always_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7 — Multi-axis aggregation and consistency checks\n",
    "\n",
    "Create a 3D array `T` with shape `(days, stores, products)`.\n",
    "Interpretation: sales units.\n",
    "\n",
    "Compute:\n",
    "\n",
    "1. Total sales per day (sum over stores and products)\n",
    "2. Total sales per store (sum over days and products)\n",
    "3. Total sales per product (sum over days and stores)\n",
    "\n",
    "Then check that all totals agree with the grand total:\n",
    "\n",
    "- `grand_total == totals_per_day.sum() == totals_per_store.sum() == totals_per_product.sum()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([153, 159, 133, 155, 149, 152, 150]),\n",
       " array([384, 317, 350]),\n",
       " array([221, 190, 200, 213, 227]),\n",
       " np.int64(1051))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "T = rng.integers(0, 20, size=(7, 3, 5))  # 7 days, 3 stores, 5 products\n",
    "\n",
    "totals_per_day = np.sum(T, axis=(1, 2))\n",
    "totals_per_store = np.sum(T, axis=(0, 2))\n",
    "totals_per_product = np.sum(T, axis=(0, 1))\n",
    "\n",
    "grand_total = np.sum(T)\n",
    "\n",
    "assert_equal(grand_total, totals_per_day.sum())\n",
    "assert_equal(grand_total, totals_per_store.sum())\n",
    "assert_equal(grand_total, totals_per_product.sum())\n",
    "\n",
    "totals_per_day, totals_per_store, totals_per_product, grand_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8 — Identify “most variable” column (std) and explain the pitfall\n",
    "\n",
    "Given dataset `D` (rows are samples, columns are features):\n",
    "\n",
    "1. Compute the standard deviation per column.\n",
    "2. Find which column is most variable.\n",
    "3. Now standardize the data (z-score per column) and recompute std.\n",
    "\n",
    "**Key insight:** after z-scoring, every column should have std ~ 1 (depending on `ddof`).\n",
    "\n",
    "Use `np.std(..., axis=0)` and z-score with broadcasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.4142, 1.0198, 7.0711]), 2, array([1., 1., 1.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.array([\n",
    "    [ 1.0,  10.0, 100.0],\n",
    "    [ 2.0,  12.0,  90.0],\n",
    "    [ 3.0,   9.0, 110.0],\n",
    "    [ 4.0,  11.0, 105.0],\n",
    "    [ 5.0,  10.0,  95.0],\n",
    "])\n",
    "\n",
    "std0 = np.std(D, axis=0)  # population std\n",
    "most_variable_col = int(np.argmax(std0))\n",
    "\n",
    "mu = np.mean(D, axis=0)\n",
    "sigma = np.std(D, axis=0)\n",
    "\n",
    "# Safe: if any sigma == 0, avoid division by zero\n",
    "Z = np.divide(D - mu, sigma, out=np.zeros_like(D), where=(sigma != 0))\n",
    "stdZ = np.std(Z, axis=0)\n",
    "\n",
    "# After z-score, std should be very close to 1 for non-constant columns\n",
    "nonconst = (sigma != 0)\n",
    "assert_close(stdZ[nonconst], np.ones(np.sum(nonconst)), atol=1e-12)\n",
    "\n",
    "std0, most_variable_col, stdZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
