{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Text Files — Practice Problems (Advanced)\n",
    "\n",
    "This notebook includes:\n",
    "\n",
    "- A set of advanced (but not too advanced) practice problems for reading text files.\n",
    "- Complete solutions following best practices (context managers, error handling, etc.).\n",
    "- A setup cell that **creates all the data files** used in the problems.\n",
    "\n",
    "⚠️ **Note:** The setup cell will (re)create several small sample files in the current directory and may overwrite files with the same names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data files created (or overwritten).\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create (or overwrite) all sample files used in this notebook.\n",
    "\n",
    "base_path = Path('.')\n",
    "\n",
    "# 1) temperatures.csv\n",
    "temperatures_content = \"\\n\".join([\n",
    "    \"date,temperature_c\",\n",
    "    \"2023-01-01,1.5\",\n",
    "    \"2023-01-02,.\",\n",
    "    \"2023-01-03,-3.0\",\n",
    "    \"2023-01-04,0.0\",\n",
    "    \"2023-01-05,invalid\",\n",
    "])\n",
    "with open(base_path / 'temperatures.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(temperatures_content)\n",
    "\n",
    "# 2) notes.txt\n",
    "notes_content = \"\\n\".join([\n",
    "    \"  This is the first note.\",\n",
    "    \"\",\n",
    "    \"Second note with some text.\",\n",
    "    \"   \",\n",
    "    \"Third note.\",\n",
    "    \"Fourth note.\",\n",
    "    \"Fifth note.\",\n",
    "    \"Sixth note.\",\n",
    "])\n",
    "with open(base_path / 'notes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(notes_content)\n",
    "\n",
    "# 3) app.log\n",
    "app_log_content = \"\\n\".join([\n",
    "    \"2025-01-01 10:00:01,INFO,App started\",\n",
    "    \"2025-01-01 10:00:03,WARNING,Low disk space\",\n",
    "    \"2025-01-01 10:00:05,ERROR,Could not open file\",\n",
    "    \"2025-01-01 10:01:01,INFO,User logged in\",\n",
    "    \"2025-01-01 10:02:00,ERROR,Unexpected input\",\n",
    "])\n",
    "with open(base_path / 'app.log', 'w', encoding='utf-8') as f:\n",
    "    f.write(app_log_content)\n",
    "\n",
    "# 4) novel.txt\n",
    "novel_content = \"\\n\".join([\n",
    "    \"The quick brown fox jumps over the lazy dog and the dog does not mind.\",\n",
    "    \"And then the fox and the dog become friends and wander through the forest.\",\n",
    "    \"In the forest, the trees are tall and the wind is soft and the night is quiet.\",\n",
    "])\n",
    "with open(base_path / 'novel.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(novel_content)\n",
    "\n",
    "# 5) rates_2025-01-01.csv, rates_2025-01-02.csv, rates_2025-01-03.csv\n",
    "rates_files = {\n",
    "    'rates_2025-01-01.csv': [\n",
    "        'date,currency,rate',\n",
    "        '2025-01-01,USD,1.10',\n",
    "        '2025-01-01,EUR,1.00',\n",
    "        '2025-01-01,GBP,0.85',\n",
    "    ],\n",
    "    'rates_2025-01-02.csv': [\n",
    "        'date,currency,rate',\n",
    "        '2025-01-02,USD,1.11',\n",
    "        '2025-01-02,EUR,1.00',\n",
    "        '2025-01-02,GBP,0.86',\n",
    "    ],\n",
    "    'rates_2025-01-03.csv': [\n",
    "        'date,currency,rate',\n",
    "        '2025-01-03,USD,1.15',\n",
    "        '2025-01-03,EUR,1.01',\n",
    "        '2025-01-03,GBP,0.87',\n",
    "    ],\n",
    "}\n",
    "for filename, lines in rates_files.items():\n",
    "    with open(base_path / filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# 6) measurements.csv\n",
    "measurements_content = \"\\n\".join([\n",
    "    'id,value',\n",
    "    '1,3.14',\n",
    "    '2,2.71',\n",
    "    '3,abc',\n",
    "    '4,.',\n",
    "    '5,10.0',\n",
    "    'six,6.0',\n",
    "])\n",
    "with open(base_path / 'measurements.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(measurements_content)\n",
    "\n",
    "# 7) students.csv\n",
    "students_content = \"\\n\".join([\n",
    "    'name,age',\n",
    "    'Alice,20',\n",
    "    'Bob,22',\n",
    "    'Charlie,invalid',\n",
    "])\n",
    "with open(base_path / 'students.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(students_content)\n",
    "\n",
    "# 8) products.csv\n",
    "products_content = \"\\n\".join([\n",
    "    'id,price',\n",
    "    'p1,9.99',\n",
    "    'p2,14.50',\n",
    "    'p3,not_a_price',\n",
    "])\n",
    "with open(base_path / 'products.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(products_content)\n",
    "\n",
    "print('Sample data files created (or overwritten).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Guidelines (Best Practices):**\n",
    "\n",
    "- Prefer `with open(...) as f:` instead of manually calling `open` / `close`.\n",
    "- Use iteration over file objects (`for line in f:`) when you can.\n",
    "- Handle bad or missing data using `try`/`except` where appropriate.\n",
    "- Avoid loading huge files entirely into memory unless you really need to.\n",
    "- Add basic safety for missing files using `try`/`except FileNotFoundError`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1 — Filter and Aggregate CSV Data\n",
    "\n",
    "You are given a CSV file `temperatures.csv` with the following structure:\n",
    "\n",
    "```text\n",
    "date,temperature_c\n",
    "2023-01-01,1.5\n",
    "2023-01-02,.\n",
    "2023-01-03,-3.0\n",
    "...\n",
    "```\n",
    "\n",
    "* The first line is a header.\n",
    "* A `.` means the temperature value is missing.\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Write a function `load_temperatures(file_name)` that:\n",
    "   - Opens the file using a context manager.\n",
    "   - Skips the header line.\n",
    "   - Reads each remaining line, strips the newline, and splits on `','`.\n",
    "   - Converts valid temperature values to `float`.\n",
    "   - Ignores rows where the value is `.` or cannot be converted.\n",
    "   - Returns a list of `(date_str, temperature_float)` tuples.\n",
    "\n",
    "2. Using that function:\n",
    "   - Compute the minimum, maximum, and average temperature.\n",
    "   - Print them in a nicely formatted way (e.g. with 2 decimal places)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min temperature: -3.00 C\n",
      "Max temperature: 1.50 C\n",
      "Average temperature: -0.50 C\n"
     ]
    }
   ],
   "source": [
    "def load_temperatures(file_name):\n",
    "    \"\"\"Return a list of (date_str, temperature_float) from a CSV file.\n",
    "\n",
    "    - Skips the header row.\n",
    "    - Skips rows with missing or invalid numeric data.\n",
    "    - Handles missing file gracefully.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            # Skip header line (if present)\n",
    "            _ = next(f, None)\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split(',', 1)\n",
    "                if len(parts) != 2:\n",
    "                    continue\n",
    "                date_str, temp_str = parts\n",
    "                temp_str = temp_str.strip()\n",
    "                # Skip missing values\n",
    "                if temp_str == '.':\n",
    "                    continue\n",
    "                try:\n",
    "                    temperature = float(temp_str)\n",
    "                except ValueError:\n",
    "                    # Bad numeric data, skip row\n",
    "                    continue\n",
    "                data.append((date_str, temperature))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_name!r}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "file_name = 'temperatures.csv'\n",
    "\n",
    "temperatures = load_temperatures(file_name)\n",
    "if temperatures:\n",
    "    values = [t for _, t in temperatures]\n",
    "    min_temp = min(values)\n",
    "    max_temp = max(values)\n",
    "    avg_temp = sum(values) / len(values)\n",
    "    print(f'Min temperature: {min_temp:.2f} C')\n",
    "    print(f'Max temperature: {max_temp:.2f} C')\n",
    "    print(f'Average temperature: {avg_temp:.2f} C')\n",
    "else:\n",
    "    print('No valid temperature data found (or file missing).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2 — Lazy Line Reader\n",
    "\n",
    "Sometimes you don't want to load all lines into memory at once.\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Implement a generator function `iter_clean_lines(file_name)` that:\n",
    "   - Uses a context manager to open the file.\n",
    "   - Iterates over the file line by line.\n",
    "   - Strips trailing whitespace (including `\\n`) from each line.\n",
    "   - Yields only non-empty lines.\n",
    "   - Handles missing file gracefully.\n",
    "\n",
    "2. Demonstrate the generator by printing the first 5 non-empty lines of a file `notes.txt` without reading the entire file into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 non-empty lines:\n",
      "  This is the first note.\n",
      "Second note with some text.\n",
      "Third note.\n",
      "Fourth note.\n",
      "Fifth note.\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "def iter_clean_lines(file_name):\n",
    "    \"\"\"Yield stripped, non-empty lines from the given text file.\n",
    "\n",
    "    If the file does not exist, print a message and yield nothing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip()\n",
    "                if line:\n",
    "                    yield line\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_name!r}\")\n",
    "        return\n",
    "\n",
    "\n",
    "file_name = 'notes.txt'\n",
    "\n",
    "print('First 5 non-empty lines:')\n",
    "for line in islice(iter_clean_lines(file_name), 5):\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3 — Parsing a Simple Log File\n",
    "\n",
    "You have an application log file `app.log` where each line looks like this:\n",
    "\n",
    "```text\n",
    "2025-01-01 10:00:01,INFO,App started\n",
    "2025-01-01 10:00:03,WARNING,Low disk space\n",
    "2025-01-01 10:00:05,ERROR,Could not open file\n",
    "...\n",
    "```\n",
    "\n",
    "The format is:\n",
    "\n",
    "```text\n",
    "timestamp,level,message\n",
    "```\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Write a function `count_log_levels(file_name)` that:\n",
    "   - Opens the log file with a context manager.\n",
    "   - Reads it line by line.\n",
    "   - Splits each line into `timestamp`, `level`, `message` using `split(',', 2)`.\n",
    "   - Counts how many times each log `level` appears.\n",
    "   - Returns a dictionary mapping each level to its count (e.g. `{'INFO': 10, 'ERROR': 2}`).\n",
    "   - Handles missing file gracefully.\n",
    "\n",
    "2. Call the function on `app.log` and print the result in a readable way, e.g.:\n",
    "\n",
    "```text\n",
    "INFO: 10\n",
    "WARNING: 3\n",
    "ERROR: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 2\n",
      "INFO: 2\n",
      "WARNING: 1\n"
     ]
    }
   ],
   "source": [
    "def count_log_levels(file_name):\n",
    "    \"\"\"Return a dict mapping log level -> count from a log file.\n",
    "\n",
    "    Handles missing file gracefully.\n",
    "    \"\"\"\n",
    "    counts = {}\n",
    "    try:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split(',', 2)\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                try:\n",
    "                    _, level, _ = parts\n",
    "                except ValueError:\n",
    "                    # If there is no message part, skip the line\n",
    "                    continue\n",
    "                level = level.strip()\n",
    "                if not level:\n",
    "                    continue\n",
    "                counts[level] = counts.get(level, 0) + 1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_name!r}\")\n",
    "    return counts\n",
    "\n",
    "\n",
    "file_name = 'app.log'\n",
    "\n",
    "level_counts = count_log_levels(file_name)\n",
    "if level_counts:\n",
    "    for level in sorted(level_counts):\n",
    "        print(f'{level}: {level_counts[level]}')\n",
    "else:\n",
    "    print('No log data found (or file missing).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4 — Count Substring in a Large File (Chunked Reading)\n",
    "\n",
    "You need to count how many times a substring appears in a potentially very large text file `novel.txt`.  \n",
    "You don't want to load the whole file into memory at once.\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Write a function `count_substring_in_file(file_name, substring, chunk_size=4096)` that:\n",
    "   - Opens the file using a context manager.\n",
    "   - Repeatedly reads chunks of size `chunk_size` using `read(chunk_size)` until the end of the file.\n",
    "   - Counts how many times `substring` occurs in the **entire** file.\n",
    "   - Handles missing file gracefully.\n",
    "\n",
    "   > Hint: Be careful with occurrences of `substring` that might span the boundary between two chunks.  \n",
    "   > One simple strategy is to remember the last `len(substring) - 1` characters from the previous chunk and prepend them to the next chunk before counting.\n",
    "\n",
    "2. Test your function with a small `novel.txt` and a few substrings (e.g. `'the'`, `'and'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of 'the': 10\n",
      "Occurrences of 'and': 6\n"
     ]
    }
   ],
   "source": [
    "def count_substring_in_file(file_name, substring, chunk_size=4096):\n",
    "    \"\"\"Return the number of times substring appears in the file.\n",
    "\n",
    "    The implementation is memory-friendly and handles matches\n",
    "    that span across chunk boundaries. Handles missing file gracefully.\n",
    "    \"\"\"\n",
    "    if not substring:\n",
    "        raise ValueError('substring must not be empty')\n",
    "\n",
    "    total = 0\n",
    "    tail = ''\n",
    "    sub_len = len(substring)\n",
    "\n",
    "    try:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            while True:\n",
    "                chunk = f.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                # Combine tail from previous chunk with current chunk\n",
    "                text = tail + chunk\n",
    "                total += text.count(substring)\n",
    "                # Keep the last sub_len - 1 characters for next round\n",
    "                if sub_len > 1:\n",
    "                    tail = text[-(sub_len - 1):]\n",
    "                else:\n",
    "                    tail = ''\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_name!r}\")\n",
    "        return 0\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "file_name = 'novel.txt'\n",
    "\n",
    "print('Occurrences of \\'the\\':', count_substring_in_file(file_name, 'the'))\n",
    "print('Occurrences of \\'and\\':', count_substring_in_file(file_name, 'and'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 5 — Merging Data from Multiple Files\n",
    "\n",
    "Suppose you receive daily CSV files with exchange rates, named like this:\n",
    "\n",
    "- `rates_2025-01-01.csv`\n",
    "- `rates_2025-01-02.csv`\n",
    "- `rates_2025-01-03.csv`\n",
    "- ...\n",
    "\n",
    "Each file has the structure:\n",
    "\n",
    "```text\n",
    "date,currency,rate\n",
    "2025-01-01,USD,1.10\n",
    "2025-01-01,EUR,1.00\n",
    "...\n",
    "```\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Write a function `load_rates(file_names)` that:\n",
    "   - Accepts a list of file names.\n",
    "   - For each file:\n",
    "     - Uses a context manager to open the file.\n",
    "     - Skips the header.\n",
    "     - Reads each line, strips it, and splits on `','`.\n",
    "     - Converts `rate` to `float`.\n",
    "     - Collects tuples of `(date_str, currency_str, rate_float)`.\n",
    "   - Returns a single list containing data from **all** the files.\n",
    "   - Handles missing files gracefully.\n",
    "\n",
    "2. Using `load_rates`, given a list of several file names, build a dictionary mapping each currency to its **average** rate across all dates (e.g. `{'USD': 1.12, 'EUR': 1.0, ...}`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rate per currency:\n",
      "EUR: 1.0033\n",
      "GBP: 0.8600\n",
      "USD: 1.1200\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def load_rates(file_names):\n",
    "    \"\"\"Load (date, currency, rate) tuples from multiple CSV files.\n",
    "\n",
    "    Skips lines with invalid data and prints a message for missing files.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            with open(file_name, encoding='utf-8') as f:\n",
    "                # Skip header\n",
    "                _ = next(f, None)\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    parts = line.split(',')\n",
    "                    if len(parts) != 3:\n",
    "                        continue\n",
    "                    date_str, currency, rate_str = parts\n",
    "                    try:\n",
    "                        rate = float(rate_str)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    all_data.append((date_str, currency, rate))\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found (skipping): {file_name!r}\")\n",
    "            continue\n",
    "    return all_data\n",
    "\n",
    "\n",
    "file_names = [\n",
    "    'rates_2025-01-01.csv',\n",
    "    'rates_2025-01-02.csv',\n",
    "    'rates_2025-01-03.csv',\n",
    "]\n",
    "\n",
    "all_rates = load_rates(file_names)\n",
    "\n",
    "if all_rates:\n",
    "    sums = defaultdict(float)\n",
    "    counts = defaultdict(int)\n",
    "\n",
    "    for _, currency, rate in all_rates:\n",
    "        sums[currency] += rate\n",
    "        counts[currency] += 1\n",
    "\n",
    "    avg_rates = {currency: sums[currency] / counts[currency] for currency in counts}\n",
    "\n",
    "    print('Average rate per currency:')\n",
    "    for currency in sorted(avg_rates):\n",
    "        print(f'{currency}: {avg_rates[currency]:.4f}')\n",
    "else:\n",
    "    print('No rate data found (files missing or empty).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 6 — Robust CSV Parsing with Error Logging\n",
    "\n",
    "You are processing a file `measurements.csv` with the following structure:\n",
    "\n",
    "```text\n",
    "id,value\n",
    "1,3.14\n",
    "2,2.71\n",
    "3,abc\n",
    "4,.\n",
    "5,10.0\n",
    "...\n",
    "```\n",
    "\n",
    "Some rows contain invalid numeric data (`abc`, `.`, empty values, etc.).\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Write a function `load_measurements(data_file, error_file)` that:\n",
    "   - Opens `data_file` for reading *and* `error_file` for writing using two context managers in a single `with` statement.\n",
    "   - Skips the header of `data_file`.\n",
    "   - For each remaining line:\n",
    "     - Strips the line and skips it if it is empty.\n",
    "     - Attempts to parse `id` as `int` and `value` as `float`.\n",
    "     - If both conversions succeed, stores the result in a list of `(id_int, value_float)` tuples.\n",
    "     - If a conversion fails, writes the **original line** to `error_file` and continues.\n",
    "   - Returns the list of successfully parsed tuples.\n",
    "   - Handles missing `data_file` gracefully (and does not create an empty `error_file` in that case).\n",
    "\n",
    "2. Call `load_measurements('measurements.csv', 'bad_measurements.csv')` and then:\n",
    "   - Print how many rows were valid.\n",
    "   - Print how many rows were written to the error file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid rows: 3\n",
      "Invalid rows (logged to bad_measurements.csv): 3\n"
     ]
    }
   ],
   "source": [
    "def load_measurements(data_file, error_file):\n",
    "    \"\"\"Load (id, value) tuples from data_file and log bad rows to error_file.\n",
    "\n",
    "    Handles missing data_file gracefully.\n",
    "    \"\"\"\n",
    "    good_rows = []\n",
    "\n",
    "    try:\n",
    "        with open(data_file, encoding='utf-8') as data_f, open(error_file, 'w', encoding='utf-8') as err_f:\n",
    "            # Skip header\n",
    "            _ = next(data_f, None)\n",
    "            for line in data_f:\n",
    "                # Preserve the original line (without trailing newline) for logging\n",
    "                raw_line = line.rstrip('\\n')\n",
    "                stripped = raw_line.strip()\n",
    "                if not stripped:\n",
    "                    continue\n",
    "                parts = stripped.split(',', 1)\n",
    "                if len(parts) != 2:\n",
    "                    err_f.write(raw_line + '\\n')\n",
    "                    continue\n",
    "                id_str, value_str = parts\n",
    "                id_str = id_str.strip()\n",
    "                value_str = value_str.strip()\n",
    "                try:\n",
    "                    id_int = int(id_str)\n",
    "                    value_float = float(value_str)\n",
    "                except ValueError:\n",
    "                    err_f.write(raw_line + '\\n')\n",
    "                    continue\n",
    "                good_rows.append((id_int, value_float))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Data file not found: {data_file!r}\")\n",
    "        return good_rows\n",
    "\n",
    "    return good_rows\n",
    "\n",
    "\n",
    "data_file = 'measurements.csv'\n",
    "error_file = 'bad_measurements.csv'\n",
    "\n",
    "good_rows = load_measurements(data_file, error_file)\n",
    "valid_count = len(good_rows)\n",
    "\n",
    "# Count invalid rows if the error file exists\n",
    "invalid_count = 0\n",
    "try:\n",
    "    with open(error_file, encoding='utf-8') as f:\n",
    "        for _ in f:\n",
    "            invalid_count += 1\n",
    "except FileNotFoundError:\n",
    "    # If the data file was missing, we might not have an error file either\n",
    "    invalid_count = 0\n",
    "\n",
    "print(f'Valid rows: {valid_count}')\n",
    "print(f'Invalid rows (logged to {error_file}): {invalid_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 7 — Reusing File-Reading Logic\n",
    "\n",
    "You need to work with several different CSV files that all share the same basic structure:\n",
    "\n",
    "```text\n",
    "# Example: any_data.csv\n",
    "col1,col2,col3\n",
    "a,1,2.0\n",
    "b,3,4.5\n",
    "...\n",
    "```\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. Write a general-purpose function `read_csv_rows(file_name, has_header=True)` that:\n",
    "   - Opens the file using a context manager.\n",
    "   - Optionally skips the first line if `has_header` is `True`.\n",
    "   - Iterates over remaining lines:\n",
    "     - Strips the line, skips it if empty.\n",
    "     - Splits on `','`.\n",
    "     - Yields the resulting list of string fields (i.e. `['a', '1', '2.0']`).\n",
    "   - Handles missing file gracefully.\n",
    "\n",
    "2. Show how you can reuse this function for two different files:\n",
    "   - `students.csv`:\n",
    "     ```text\n",
    "     name,age\n",
    "     Alice,20\n",
    "     Bob,22\n",
    "     ```\n",
    "   - `products.csv`:\n",
    "     ```text\n",
    "     id,price\n",
    "     p1,9.99\n",
    "     p2,14.50\n",
    "     ```\n",
    "\n",
    "   For each file, use `read_csv_rows` to:\n",
    "   - Print all rows.\n",
    "   - Convert numeric fields (`age`, `price`) to the appropriate numeric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students:\n",
      "- Alice: 20 years old\n",
      "- Bob: 22 years old\n",
      "\n",
      "Products:\n",
      "- p1: 9.99\n",
      "- p2: 14.50\n"
     ]
    }
   ],
   "source": [
    "def read_csv_rows(file_name, has_header=True):\n",
    "    \"\"\"Yield lists of string fields for each non-empty row in a CSV file.\n",
    "\n",
    "    Handles missing file gracefully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_name, encoding='utf-8') as f:\n",
    "            if has_header:\n",
    "                _ = next(f, None)\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                fields = [field.strip() for field in line.split(',')]\n",
    "                yield fields\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_name!r}\")\n",
    "        return\n",
    "\n",
    "\n",
    "# Example usage with students.csv and products.csv:\n",
    "\n",
    "students_file = 'students.csv'\n",
    "products_file = 'products.csv'\n",
    "\n",
    "students = []\n",
    "for row in read_csv_rows(students_file):\n",
    "    if len(row) != 2:\n",
    "        continue\n",
    "    name, age_str = row\n",
    "    try:\n",
    "        age = int(age_str)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    students.append((name, age))\n",
    "\n",
    "products = []\n",
    "for row in read_csv_rows(products_file):\n",
    "    if len(row) != 2:\n",
    "        continue\n",
    "    product_id, price_str = row\n",
    "    try:\n",
    "        price = float(price_str)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    products.append((product_id, price))\n",
    "\n",
    "print('Students:')\n",
    "for name, age in students:\n",
    "    print(f'- {name}: {age} years old')\n",
    "\n",
    "print('\\nProducts:')\n",
    "for product_id, price in products:\n",
    "    print(f'- {product_id}: {price:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
